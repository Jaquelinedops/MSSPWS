{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaque\\AppData\\Local\\Temp\\ipykernel_27012\\1819983139.py:38: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import GridSearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package english_wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package english_wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package mock_corpus to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mock_corpus is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jaque\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070 Ti\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Ti\n",
      "Total VRAM: 11.99 GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, Dense, SpatialDropout1D,\n",
    "    Bidirectional, Attention, GlobalAveragePooling1D, Dropout,\n",
    "    Layer,  # Import the Layer class\n",
    "    Multiply # Import the Multiply layer\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Dropout, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import HyperParameters, GridSearch, Objective\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from kerastuner import GridSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner import Objective # Import directly from kerastuner\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from kerastuner.tuners import GridSearch  # Import GridSearch tuner\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "# Download required NLTK data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "import pandas as pd # Assuming your data is in a pandas DataFrame\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder # If labels are strings\n",
    "from imblearn.under_sampling import RandomUnderSampler #added\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,  StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "path_source_code = ''\n",
    "from urllib.parse import urlparse\n",
    "import tqdm\n",
    "from xgboost import XGBClassifier  # Make sure this import is included\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Dropout, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import HyperParameters, GridSearch, Objective\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import sys\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sys.path.append(path_source_code) # Replace with the actual path to the directory containing pdf_preprosseing.py\n",
    "from pre_processing import get_only_words_from_strings, remove_stop_words, extract_entities,  hash_content, correct_text,plot_confusion_matrix, extract_unique_values, replace_entity, detect_words_segment , find_emails,find_links,extract_radical, remove_numbers , identify_frequent_short_words\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "from scipy.sparse import issparse\n",
    "import joblib\n",
    "import random\n",
    "# Set random seeds\n",
    "\n",
    "import torch\n",
    "# ---- Load NER models ----\n",
    "\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "print(torch.cuda.is_available())            # ‚úÖ Should be True\n",
    "print(torch.cuda.get_device_name(0))        # Should show your GPU name\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Total VRAM:\", round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2), \"GB\")\n",
    "else:\n",
    "    print(\"CUDA not available. GPU not detected.\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = tf.keras.metrics.Precision()\n",
    "        self.recall = tf.keras.metrics.Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.round(y_pred)\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_entities(batch):\n",
    "    ner_results = date_ner(batch[\"content_no_entity\"])  # Use RoBERTa pipeline\n",
    "\n",
    "    new_texts, orgs_list, pers_list, locs_list, miscs_list, dates_list = [], [], [], [], [], []\n",
    "\n",
    "    for i, text in enumerate(batch[\"content_no_entity\"]):\n",
    "        ents = ner_results[i]\n",
    "\n",
    "        dates = [e[\"word\"] for e in ents if e[\"entity_group\"] == \"DATE\"]\n",
    "        orgs  = [e[\"word\"] for e in ents if e[\"entity_group\"] == \"ORG\"]\n",
    "        pers  = [e[\"word\"] for e in ents if e[\"entity_group\"] == \"PER\"]\n",
    "        locs  = [e[\"word\"] for e in ents if e[\"entity_group\"] == \"LOC\"]\n",
    "        miscs = [e[\"word\"] for e in ents if e[\"entity_group\"] == \"MISC\"]\n",
    "\n",
    "        # Replace entities\n",
    "        anonymized = text\n",
    "        anonymized = replace_entity(anonymized, dates, \" [[DATE]] \")\n",
    "        anonymized = replace_entity(anonymized, orgs,  \" [[ORG]] \")\n",
    "        anonymized = replace_entity(anonymized, pers,  \" [[PER]] \")\n",
    "        anonymized = replace_entity(anonymized, locs,  \" [[LOC]] \")\n",
    "        anonymized = replace_entity(anonymized, miscs, \" [[MISC]] \")\n",
    "\n",
    "        # Append results\n",
    "        new_texts.append(anonymized)\n",
    "        orgs_list.append(list(set(orgs)))\n",
    "        pers_list.append(list(set(pers)))\n",
    "        locs_list.append(list(set(locs)))\n",
    "        miscs_list.append(list(set(miscs)))\n",
    "        dates_list.append(list(set(dates)))\n",
    "\n",
    "    return {\n",
    "        \"content_no_entity\": new_texts,\n",
    "        \"org\": orgs_list,\n",
    "        \"person\": pers_list,\n",
    "        \"location\": locs_list,\n",
    "        \"misc\": miscs_list,\n",
    "        \"date\": dates_list\n",
    "    }\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove weird spacing\n",
    "    return text.strip().title()  # Capitalize normally\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment\n",
    "Processador\t13th Gen Intel(R) Core(TM) i9-13900K   3.00 GHz\n",
    "24 Cores\n",
    "RAM instalada\t64,0 GB (utiliz√°vel: 63,7 GB)\n",
    "Tipo de sistema\tSistema operacional de 64 bits, processador baseado em x64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file modern_slavery_NER_us_india_val1.csv is already placed at this path\n"
     ]
    }
   ],
   "source": [
    "##Data cleaning and preparation \n",
    "file_path = os.path.join(path_source_code, \"modern_slavery_NER_us_india_val1.csv\")\n",
    "file_path2 = os.path.join(path_source_code, \"modern_slavery_NER_us_india_val1.csv\")\n",
    "if not (os.path.exists(file_path) and os.path.exists(file_path2)):\n",
    "    df = pd.read_csv('modern_slavery_NER_us_india_val1.csv', index_col=0)\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    df = df.dropna(subset=[\"content\"])\n",
    "\n",
    "    df = df.dropna(subset=[\"content\"])\n",
    "\n",
    "    columns_to_clean = [\n",
    "    'human_trafficking', 'forced_labor', 'child_labor',\n",
    "    'sex_trafficking', 'drug_trafficking',\n",
    "    'modern_slavery', 'modern_slavery_in_supply_chain'\n",
    "    ]\n",
    "\n",
    "    for col in tqdm(columns_to_clean, desc=\"Limpando colunas de categorias\"):\n",
    "        # Converte tudo para string e min√∫sculas\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "        \n",
    "        # Substitui valores diferentes de 'yes' ou 'no' por 'no'\n",
    "        df[col] = df[col].where(df[col].isin(['yes', 'no']), 'no')\n",
    "\n",
    "    #identify entities and input placeholders\n",
    "    df['email'] = df['content'].apply(find_emails)\n",
    "    df['email'] = df['email'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['email'] = df['email'].apply(lambda x: list(set(x)) if isinstance(x, list) else x)\n",
    "    unique_emails = extract_unique_values(df, 'email')\n",
    "    df['content_no_entity'] = df['content'].apply(lambda x: replace_entity(x, unique_emails, \" [[EMAIL]] \"))\n",
    "\n",
    "    df['links'] = df['content_no_entity'].apply(find_links)\n",
    "    df['links'] = df['links'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['links'] = df['links'].apply(lambda x: list(set(x)) if isinstance(x, list) else x)\n",
    "    unique_links = extract_unique_values(df, 'links')\n",
    "    df['content_no_entity'] = df['content_no_entity'].apply(lambda x: replace_entity(x, unique_links, \" [[LINK]] \"))\n",
    "    unique_links2 =[extract_radical(url) for url in unique_links]\n",
    "    df['content_no_entity'] = df['content_no_entity'].apply(lambda x: replace_entity(x, unique_links2, \" [[LINK]] \"))\n",
    "    #----\n",
    "    df = df[df[\"content_no_entity\"].notna()].copy()\n",
    "    texts = df[\"content_no_entity\"].tolist()\n",
    "  \n",
    "    # Run batch NER\n",
    "    #docs = list(nlp.pipe(texts, batch_size=32))\n",
    "\n",
    "    # Process each doc into anonymized text + entities\n",
    "    #results = [identify_entities(doc) for doc in docs]\n",
    "\n",
    "    # Unpack results\n",
    "    #df[\"content_no_entity\"] = [r[0] for r in results]\n",
    "    #df[\"org\"] = [list(set(r[1])) for r in results]\n",
    "    #df[\"person\"] = [list(set(r[2])) for r in results]\n",
    "    #df[\"location\"] = [list(set(r[3])) for r in results]\n",
    "    #df[\"date\"] = [list(set(r[4])) for r in results]\n",
    "    #df[\"GPE\"] = [list(set(r[5])) for r in results]\n",
    "\n",
    "    \n",
    "    # ---- Load RoBERTa NER pipeline with DATE support ----\n",
    "    date_ner = pipeline(\n",
    "        \"ner\",\n",
    "        model=\"Jean-Baptiste/roberta-large-ner-english\",\n",
    "        tokenizer=\"Jean-Baptiste/roberta-large-ner-english\",\n",
    "        aggregation_strategy=\"simple\",\n",
    "        device=0,        # GPU\n",
    "        batch_size=16    # Adjust based on memory\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # ---- Prepare dataset ----\n",
    "    df = df[df[\"content_no_entity\"].notna()].copy().reset_index(drop=True)\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "    # ---- Run batched NER ----\n",
    "    dataset = dataset.map(identity_entities, batched=True, batch_size=16)\n",
    "    custom_stop_words = []\n",
    "\n",
    "    # ---- Convert to DataFrame if needed ----\n",
    "    df_result = dataset.to_pandas()\n",
    "    df_result['content_corrected'] = df_result['content_no_entity'].astype(str).str.lower().apply(lambda text: remove_stop_words(text,custom_stop_words))\n",
    "    df_result.to_csv(\"modern_slavery_NER_us_india.csv\", index=False)\n",
    "    # üîπ Step 1: Convert list columns into a long format using `melt`\n",
    "    df_melted = df_result.melt(id_vars=['id'], value_vars=['location', 'org', 'person', 'date', 'email', 'links', 'misc'], var_name='entity_type', value_name='entity')\n",
    "    # üîπ Step 2: Explode the 'entity' column (previously stored as lists)\n",
    "    df_melted['entity'] = df_melted['entity'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "    df_exploded = df_melted.explode('entity', ignore_index=True)\n",
    "    df_exploded = df_exploded[df_exploded[\"entity\"].astype(str) != \"[]\"]\n",
    "    df_exploded.to_csv('modern_slavery_ENTITIES_related_us_india.csv')\n",
    "\n",
    "else:\n",
    "    print(\"A file \" + str(file_path2) + ' is already placed at this path')\n",
    "    df = pd.read_csv('modern_slavery_NER_us_india_val1.csv',index_col =0 )\n",
    "    df = df.drop_duplicates()\n",
    "    df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data distribution visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem das novas classes criadas:\n",
      "target\n",
      "not a modern_slavery              1752\n",
      "modern_slavery in supply chain     311\n",
      "modern_slavery                      87\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Carregar o DataFrame ---\n",
    "try:\n",
    "    df = pd.read_csv('modern_slavery_NER_us_india_val1.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: O arquivo 'modern_slavery_NER_us_india_val1.csv' n√£o foi encontrado.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Limpeza e convers√£o para min√∫sculas (boa pr√°tica) ---\n",
    "df['modern_slavery'] = df['modern_slavery'].str.lower()\n",
    "df['modern_slavery_in_supply_chain'] = df['modern_slavery_in_supply_chain'].str.lower()\n",
    "\n",
    "# --- 3. Cria√ß√£o da nova coluna de r√≥tulo com a l√≥gica das tr√™s classes ---\n",
    "# Definir as condi√ß√µes\n",
    "conditions = [\n",
    "    # Condi√ß√£o 1: A escravatura moderna est√° na cadeia de abastecimento\n",
    "    (df['modern_slavery'] == 'yes') & (df['modern_slavery_in_supply_chain'] == 'yes'),\n",
    "    # Condi√ß√£o 2: √â escravatura moderna, mas n√£o na cadeia de abastecimento\n",
    "    (df['modern_slavery'] == 'yes') & (df['modern_slavery_in_supply_chain'] == 'no'),\n",
    "    # Condi√ß√£o 3: N√£o √© escravatura moderna\n",
    "    (df['modern_slavery'] == 'no')\n",
    "]\n",
    "\n",
    "# Definir os r√≥tulos correspondentes\n",
    "labels = [\n",
    "    'modern_slavery in supply chain',\n",
    "    'modern_slavery',\n",
    "    'not a modern_slavery'\n",
    "]\n",
    "\n",
    "# Usar np.select para criar a nova coluna de forma limpa e eficiente\n",
    "df['target'] = np.select(conditions, labels, default='not a modern_slavery')\n",
    "\n",
    "# --- 4. Verifica√ß√£o dos resultados ---\n",
    "print(\"Contagem das novas classes criadas:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lista das colunas categ√≥ricas bin√°rias\n",
    "df = df.drop_duplicates(subset='id')\n",
    "\n",
    "# Lista das colunas categ√≥ricas bin√°rias\n",
    "columns = [\n",
    "    'human_trafficking', 'forced_labor', 'child_labor',\n",
    "    'sex_trafficking', 'modern_slavery', 'modern_slavery_in_supply_chain'\n",
    "]\n",
    "\n",
    "# Conta quantos 'yes' tem em cada coluna\n",
    "yes_counts = {col: (df[col].str.lower() == 'yes').sum() for col in columns}\n",
    "\n",
    "# Adiciona a categoria 'not_modern_slavery'\n",
    "yes_counts['not_modern_slavery'] = (df['modern_slavery'].str.lower() !=  'yes').sum()\n",
    "\n",
    "# Converte para DataFrame\n",
    "plot_df = pd.DataFrame(list(yes_counts.items()), columns=['Categoria', 'Total'])\n",
    "\n",
    "# Ordena do menor para o maior (para barras de cima pra baixo)\n",
    "plot_df = plot_df.sort_values(by='Total', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Gr√°fico de barras horizontal\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=plot_df, y='Categoria', x='Total', palette='Blues_d')\n",
    "\n",
    "# Ajuste dos n√∫meros ao lado das barras\n",
    "for index, row in plot_df.iterrows():\n",
    "    ax.text(\n",
    "        row['Total'] + max(plot_df['Total']) * 0.01,  # deslocamento proporcional\n",
    "        index,\n",
    "        str(row['Total']),\n",
    "        va='center',\n",
    "        ha='left',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title(\"Quantity cases by label\", fontsize=14)\n",
    "plt.xlabel(\"Number of cases\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Contagem total por fonte\n",
    "total_counts = df['source'].value_counts().reset_index()\n",
    "total_counts.columns = ['source', 'total']\n",
    "\n",
    "# Contagem de modern_slavery_in_supply_chain == 'yes'\n",
    "supply_chain_counts = df[df['modern_slavery_in_supply_chain'].str.lower() == 'yes']['source'].value_counts().reset_index()\n",
    "supply_chain_counts.columns = ['source', 'modern_slavery_in_supply_chain']\n",
    "\n",
    "# Contagem de modern_slavery == 'yes'\n",
    "modern_slavery_counts = df[df['modern_slavery'].str.lower() == 'yes']['source'].value_counts().reset_index()\n",
    "modern_slavery_counts.columns = ['source', 'modern_slavery']\n",
    "\n",
    "not_modern_slavery_counts = df[df['modern_slavery'].str.lower() != 'yes']['source'].value_counts().reset_index()\n",
    "not_modern_slavery_counts.columns = ['source', 'not_modern_slavery']\n",
    "\n",
    "# Merge de todos os DataFrames\n",
    "merged = total_counts.merge(supply_chain_counts, on='source', how='left') \\\n",
    "                     .merge(modern_slavery_counts, on='source', how='left') \\\n",
    "                     .merge(not_modern_slavery_counts, on='source', how='left')\n",
    "\n",
    "# Substitui NaN por 0 e ajusta tipo\n",
    "merged.fillna(0, inplace=True)\n",
    "merged[['not_modern_slavery','modern_slavery_in_supply_chain', 'modern_slavery']]= merged[['not_modern_slavery','modern_slavery_in_supply_chain', 'modern_slavery']].astype(int)\n",
    "\n",
    "# Formato longo para o seaborn\n",
    "long_df = pd.melt(\n",
    "    merged,\n",
    "    id_vars='source',\n",
    "    value_vars=['total', 'not_modern_slavery', 'modern_slavery','modern_slavery_in_supply_chain'],\n",
    "    var_name='category',\n",
    "    value_name='count'\n",
    ")\n",
    "\n",
    "# Define cores personalizadas para cada categoria\n",
    "palette = {\n",
    "    'total': '#012345',         # Azul escuro\n",
    "    'not_modern_slavery':'#0000FF',\n",
    "    'modern_slavery': '#00BFFF',  # po azul\n",
    "    'modern_slavery_in_supply_chain': '#B0C4DE', # Azul claro\n",
    "\n",
    "}\n",
    "\n",
    "# Gr√°fico de barras lado a lado com cores e legenda colorida\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(data=long_df, x='source', y='count', hue='category', palette='Blues_d')\n",
    "\n",
    "# N√∫meros acima de cada barra\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height > 0:\n",
    "        ax.annotate(\n",
    "            f'{int(height)}',\n",
    "            (p.get_x() + p.get_width() / 2., height),\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=10, color='black', xytext=(0, 4),\n",
    "            textcoords='offset points'\n",
    "        )\n",
    "\n",
    "# T√≠tulos e legenda final\n",
    "plt.title(\"Number of cases by source and label\", fontsize=14)\n",
    "plt.ylabel(\"Number of cases\")\n",
    "plt.xlabel(\"Source\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# A legenda j√° reflete as cores das colunas por causa da paleta\n",
    "plt.legend(title='Count by category', title_fontsize=12, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold_results = []\n",
    "time_to_predict = []\n",
    "test_result = pd.DataFrame()\n",
    "\n",
    "\n",
    "def train_model_with_gridsearch(\n",
    "    model_name,\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='recall',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    sample_weights =None\n",
    "):\n",
    "    print(f\"\\n{model_name}: Training the model...\")\n",
    "\n",
    "    # Initial pipeline fit (optional pre-training step)\n",
    "    start_time = time.time()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_time = (time.time() - start_time) * 1000\n",
    "    print(f\"Initial Training Time: {train_time:.4f} ms\")\n",
    "\n",
    "    # Grid Search\n",
    "    print(f\"\\n{model_name}: Running GridSearchCV...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        verbose=verbose,\n",
    "        n_jobs=-1,\n",
    "\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best CV Score:\", grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_     \n",
    "\n",
    "    return best_model, grid_search, train_time\n",
    "\n",
    "def ci95(values):\n",
    "    \"\"\"Return 95% confidence interval as (lower, upper).\"\"\"\n",
    "    mean = np.mean(values)\n",
    "    se = stats.sem(values)\n",
    "    h = 1.96 * se\n",
    "    return mean - h, mean + h\n",
    "\n",
    "def bootstrap_ci(y_true, y_pred, metric_func, n_boot=2000):\n",
    "    \"\"\"95% bootstrap confidence interval for test metric.\"\"\"\n",
    "    n = len(y_true)\n",
    "    boot_vals = []\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        boot_vals.append(metric_func(y_true[idx], y_pred[idx]))\n",
    "\n",
    "    return np.mean(boot_vals), np.std(boot_vals), np.percentile(boot_vals, 2.5), np.percentile(boot_vals, 97.5)\n",
    "\n",
    "def evaluate_pipeline_model(pipeline, model_name, X_train, y_train, X_test, y_test, kf,\n",
    "                            test_result, nfold_results, time_to_predict, train_time):\n",
    "\n",
    "    print(f\"\\n--- Evaluating Model: {model_name} ---\")\n",
    "\n",
    "    # === Cross-validation ===\n",
    "    print(\"Performing cross-validation...\")\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"precision_weighted\": \"precision_weighted\",\n",
    "        \"recall_weighted\": \"recall_weighted\",\n",
    "        \"f1_weighted\": \"f1_weighted\"\n",
    "    }\n",
    "\n",
    "    cv_scores = {}\n",
    "    cv_summary = {}  # <- now defined\n",
    "\n",
    "    # Compute CV results\n",
    "    for key, scoring in metrics.items():\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=kf,\n",
    "                                 scoring=scoring, n_jobs=-1)\n",
    "\n",
    "        cv_scores[key] = scores\n",
    "\n",
    "        mean = scores.mean()\n",
    "        std = scores.std()\n",
    "        low, high = ci95(scores)\n",
    "\n",
    "        cv_summary[key] = {\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"ci_low\": low,\n",
    "            \"ci_high\": high\n",
    "        }\n",
    "\n",
    "        print(f\"\\n{key.upper()} CV: mean={mean:.4f}, std={std:.4f}, 95% CI=({low:.4f}, {high:.4f})\")\n",
    "        print(f\"All CV scores for {key}: {scores}\")\n",
    "\n",
    "    # === Test set evaluation ===\n",
    "    print(\"\\nPredicting on test set...\")\n",
    "    start_time = time.time()\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    pred_time_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "    print(f\"Prediction time: {pred_time_ms:.4f} ms\")\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # Test metrics\n",
    "    test_metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision_weighted\": precision_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"recall_weighted\": recall_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"f1_weighted\": f1_score(y_test, y_pred, average=\"weighted\", zero_division=0),\n",
    "    }\n",
    "\n",
    "    # Print bootstrap CIs for test metrics\n",
    "    print(\"\\nTest Metrics with 95% bootstrap CIs:\")\n",
    "    metric_funcs = {\n",
    "        \"accuracy\": accuracy_score,\n",
    "        \"precision_weighted\": lambda yt, yp: precision_score(yt, yp, average='weighted', zero_division=0),\n",
    "        \"recall_weighted\": lambda yt, yp: recall_score(yt, yp, average='weighted', zero_division=0),\n",
    "        \"f1_weighted\": lambda yt, yp: f1_score(yt, yp, average='weighted', zero_division=0),\n",
    "    }\n",
    "\n",
    "    for m, val in test_metrics.items():\n",
    "        mean_b, std_b, low_b, high_b = bootstrap_ci(\n",
    "            np.array(y_test),\n",
    "            np.array(y_pred),\n",
    "            metric_func=metric_funcs[m]\n",
    "        )\n",
    "        print(f\"{m}: {val:.4f} | bootstrap mean={mean_b:.4f}, std={std_b:.4f}, 95% CI=({low_b:.4f}, {high_b:.4f})\")\n",
    "\n",
    "    # === Update test_result DataFrame ===\n",
    "    if not isinstance(test_result, pd.DataFrame):\n",
    "        test_result = pd.DataFrame()\n",
    "\n",
    "    if \"Model\" in test_result.columns:\n",
    "        test_result = test_result[test_result[\"Model\"] != model_name].copy()\n",
    "\n",
    "    # Final row: raw test metrics + CV std\n",
    "    result_row = {\n",
    "        \"Model\": model_name,\n",
    "\n",
    "        # Raw test metrics\n",
    "        \"Accuracy\": round(test_metrics[\"accuracy\"] * 100, 4),\n",
    "        \"Precision\": round(test_metrics[\"precision_weighted\"] * 100, 4),\n",
    "        \"Recall\": round(test_metrics[\"recall_weighted\"] * 100, 4),\n",
    "        \"F1 Score\": round(test_metrics[\"f1_weighted\"] * 100, 4),\n",
    "\n",
    "        # NEW ‚Äî cross-validation standard deviations\n",
    "        \"cv_std_accuracy\": round(cv_summary[\"accuracy\"][\"std\"] * 100, 4),\n",
    "        \"cv_std_precision\": round(cv_summary[\"precision_weighted\"][\"std\"] * 100, 4),\n",
    "        \"cv_std_recall\": round(cv_summary[\"recall_weighted\"][\"std\"] * 100, 4),\n",
    "        \"cv_std_f1\": round(cv_summary[\"f1_weighted\"][\"std\"] * 100, 4),\n",
    "\n",
    "        \"Time to Predict (ms)\": pred_time_ms\n",
    "    }\n",
    "\n",
    "    test_result = pd.concat([test_result, pd.DataFrame([result_row])], ignore_index=True)\n",
    "\n",
    "    # === Store fold-level CV metrics ===\n",
    "    nfold_results = [m for m in nfold_results if m[\"model\"] != model_name]\n",
    "    nfold_results.append({\n",
    "        \"model\": model_name,\n",
    "        \"cv_scores\": cv_scores\n",
    "    })\n",
    "\n",
    "    # timing info\n",
    "    time_to_predict.append({\n",
    "        \"model\": model_name,\n",
    "        \"train_time\": train_time,\n",
    "        \"prediction_time\": pred_time_ms\n",
    "    })\n",
    "\n",
    "    return test_result, nfold_results, time_to_predict, y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_grid_svm = {\n",
    "    'clf__C': [0.1, 1, 10, 100],\n",
    "    'clf__kernel': ['linear'],\n",
    "    'clf__gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'clf__degree': [2, 3],  # Only relevant for 'poly' kernel\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "    'clf__max_iter': [100, 1000, 5000],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'clf__n_estimators': [50, 100, 200, 300, 500],\n",
    "    'clf__max_depth': [3, 6, 18],\n",
    "    'clf__learning_rate': [0.01, 0.5,0.1],\n",
    "    'clf__subsample': [0.8, 1.0],\n",
    "\n",
    "}\n",
    "param_grid_lr = {\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet', None],     # Regularization type\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],             # Inverse of regularization strength\n",
    "    'clf__solver': ['saga','liblinear','lbfgs' ],                             # 'saga' supports all penalties\n",
    "    'clf__max_iter': [30, 50, 100]                    # Iteration limit\n",
    "}\n",
    "\n",
    "\n",
    "# Define hyperparameters for AdaBoost\n",
    "param_grid_adaboost = {\n",
    "    'clf__n_estimators': [50, 100, 200, 300],\n",
    "    'clf__learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'clf__estimator': [\n",
    "        DecisionTreeClassifier(max_depth=1),\n",
    "        DecisionTreeClassifier(max_depth=2)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [50, 100, 200,300],        # Number of trees in the forest\n",
    "    'clf__max_depth': [None,5, 10, 20],        # Maximum depth of the tree\n",
    "    'clf__min_samples_split': [5, 10, 15],        # Minimum number of samples required to split an internal node\n",
    "    'clf__max_features': ['sqrt', 'log2', None],# Number of features to consider when looking for the best split\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmatizerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No fitting necessary for transformation\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [\" \".join([self.lemmatizer.lemmatize(word,\"v\") for word in text.split()]) for text in X]\n",
    "\n",
    "class GloveVectorizer:\n",
    "    def __init__(self, glove, dim):\n",
    "        self.glove = glove\n",
    "        self.dim = dim\n",
    "\n",
    "    def encode(self, texts, show_progress_bar=False):\n",
    "        vectors = []\n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            word_vecs = [self.glove.get(w.lower(), np.zeros(self.dim)) for w in words]\n",
    "            if word_vecs:\n",
    "                vectors.append(np.mean(word_vecs, axis=0))\n",
    "            else:\n",
    "                vectors.append(np.zeros(self.dim))\n",
    "        return np.array(vectors)\n",
    "    \n",
    "def load_glove(path):\n",
    "    glove = {}\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector\n",
    "    return glove\n",
    "\n",
    "    \n",
    "class SentenceBERTVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', pooling='mean'):\n",
    "        self.model_name = model_name\n",
    "        self.pooling = pooling\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Ensure input is a list of strings\n",
    "        if hasattr(X, 'tolist'):\n",
    "            texts = X.tolist()\n",
    "        elif isinstance(X, list):\n",
    "            texts = X\n",
    "        else:\n",
    "            raise ValueError(\"Input X must be a Series, list, or array of strings.\")\n",
    "\n",
    "        # Embed the text using SentenceTransformer\n",
    "        return self.model.encode(texts, batch_size=32, show_progress_bar=False)\n",
    "\n",
    "def get_only_words_from_strings(text):\n",
    "    \"\"\"\n",
    "    Removes numbers, punctuation, and special characters from a given string,\n",
    "    but keeps square brackets [].\n",
    "\n",
    "    :param text: The input string to be cleaned.\n",
    "    :return: A cleaned string with only alphabetic characters, spaces, and square brackets.\n",
    "    \"\"\"\n",
    "    # Keep only letters, spaces, and square brackets\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s\\[\\]]', '', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#MULTI LAYER PERCEPTRON MODEL BUILDER\n",
    "def build_mlp(hp):\n",
    "    \"\"\"\n",
    "    Constr√≥i o modelo MLP usando hiperpar√¢metros do Keras Tuner para classifica√ß√£o bin√°ria.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hiperpar√¢metros\n",
    "    units = hp.Choice(\"units\", [64, 128, 256])\n",
    "    dropout_rate = hp.Choice(\"dropout\", [0.2, 0.3, 0.4])\n",
    "\n",
    "    # Arquitetura do Modelo\n",
    "    model.add(Dense(units, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation=\"sigmoid\")) # Sa√≠da para classifica√ß√£o bin√°ria\n",
    "\n",
    "    # Compila√ß√£o do Modelo\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            # CORRIGIDO: Usando 'average=macro' e 'name=f1_score'\n",
    "            keras.metrics.F1Score(\n",
    "                threshold=0.5,           # Limiar para classifica√ß√£o bin√°ria\n",
    "                average='macro',         # Usa a m√©dia Macro (n√£o ponderada)\n",
    "                name='f1_score'          # Nome simples para o objetivo do tuner\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ‚ùó IMPORTANT: Update the Keras Tuner Objective if you use the new name:\n",
    "# objective=Objective('f1_score_weighted', direction='max')\n",
    "\n",
    "# ‚ùó Important: Update your Keras Tuner Objective to match the new metric name:\n",
    "# objective=Objective('f1_score_weighted', direction='max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY DATASET PREPARATION ( FOR MODERN SLAVERY IN SUPPLY CHAIN DETECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Encoding\n",
    "def classify(row):\n",
    "    if str(row['modern_slavery_in_supply_chain']).strip().lower() == 'yes':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['target'] = df.apply(classify, axis=1)\n",
    "\n",
    "#cleaning\n",
    "df['content_corrected'] = df['content_corrected'].apply(get_only_words_from_strings)\n",
    "df['content_corrected'] = df['content_corrected'].str.strip()\n",
    "df= df[['content','content_corrected','target','source']].dropna()\n",
    "\n",
    "X_raw   = df['content']\n",
    "X_clean = df['content_corrected']\n",
    "y_full = df['target']\n",
    "source_full = df['source']\n",
    "#folds for validation\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_original, X_test_original, y_train_original, y_test_original, source_train, source_test = train_test_split(\n",
    "    X_clean,       \n",
    "    y_full,\n",
    "    source_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    #stratify=y_full\n",
    ")\n",
    "rus = RandomUnderSampler(random_state=SEED)\n",
    "X_train_resampled_df, y_train_resampled = rus.fit_resample(X_train_original.to_frame(), y_train_original)\n",
    "X_train_resampled = X_train_resampled_df.iloc[:, 0]\n",
    "\n",
    "# defining class weights and samples\n",
    "class_labels = np.unique(df['target'])\n",
    "class_weights_array = class_weight.compute_class_weight('balanced', classes=class_labels, y=df['target'])\n",
    "class_weights_dict = dict(zip(class_labels, class_weights_array))\n",
    "\n",
    "sample_weights = np.array([class_weights_dict[label] for label in df['target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence BERT embbeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming this class works like a wrapper for SentenceTransformer\n",
    "sbert_vectorizer = SentenceBERTVectorizer()\n",
    "X_train_bert_resampled = sbert_vectorizer.fit_transform(X_train_resampled)\n",
    "X_test_bert = sbert_vectorizer.fit_transform(X_test_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM + SBERT + undersampled: Training the model...\n",
      "Initial Training Time: 189.9791 ms\n",
      "\n",
      "SVM + SBERT + undersampled: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best Parameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__degree': 2, 'clf__gamma': 'scale', 'clf__kernel': 'linear', 'clf__max_iter': 1000}\n",
      "Best CV Score: 0.694333956152938\n",
      "\n",
      "--- Evaluating Model: SVM + SBERT + undersampled ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.6983, std=0.0358, 95% CI=(0.6750, 0.7217)\n",
      "All CV scores for accuracy: [0.76       0.64       0.7        0.72       0.69387755 0.67346939\n",
      " 0.75510204 0.69387755 0.67346939 0.67346939]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7013, std=0.0357, 95% CI=(0.6779, 0.7247)\n",
      "All CV scores for precision_weighted: [0.76683087 0.64367816 0.70292208 0.72141707 0.69394581 0.68290542\n",
      " 0.75510204 0.69758813 0.67346939 0.67517576]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.6983, std=0.0358, 95% CI=(0.6750, 0.7217)\n",
      "All CV scores for recall_weighted: [0.76       0.64       0.7        0.72       0.69387755 0.67346939\n",
      " 0.75510204 0.69387755 0.67346939 0.67346939]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.6971, std=0.0363, 95% CI=(0.6733, 0.7208)\n",
      "All CV scores for f1_weighted: [0.75845411 0.63768116 0.6989161  0.71955128 0.69362213 0.66763848\n",
      " 0.75510204 0.69311129 0.67346939 0.67319728]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 11.8842 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.80      0.87       366\n",
      "           1       0.40      0.77      0.52        64\n",
      "\n",
      "    accuracy                           0.79       430\n",
      "   macro avg       0.67      0.78      0.70       430\n",
      "weighted avg       0.87      0.79      0.82       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.7930 | bootstrap mean=0.7927, std=0.0193, 95% CI=(0.7558, 0.8302)\n",
      "precision_weighted: 0.8689 | bootstrap mean=0.8698, std=0.0157, 95% CI=(0.8369, 0.8991)\n",
      "recall_weighted: 0.7930 | bootstrap mean=0.7923, std=0.0198, 95% CI=(0.7512, 0.8302)\n",
      "f1_weighted: 0.8166 | bootstrap mean=0.8164, std=0.0171, 95% CI=(0.7827, 0.8490)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = X_train_bert_resampled\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_bert\n",
    "y_test = y_test_original\n",
    "# Assuming y_train contains your training labels (e.g., 0 and 1)\n",
    "\n",
    "\n",
    "model_name = \"SVM + SBERT + undersampled\"\n",
    "pipeline_bert_svm = Pipeline([\n",
    "    ('clf', SVC(  probability=True, random_state=SEED))  # probability=True for predict_proba if needed\n",
    "])\n",
    "\n",
    "pipeline = pipeline_bert_svm\n",
    "param_grid = param_grid_svm\n",
    "\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = 'f1'\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_svm_bert = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>cv_std_accuracy</th>\n",
       "      <th>cv_std_precision</th>\n",
       "      <th>cv_std_recall</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>Time to Predict (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM + SBERT + undersampled</td>\n",
       "      <td>79.30</td>\n",
       "      <td>86.89</td>\n",
       "      <td>79.30</td>\n",
       "      <td>81.66</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.63</td>\n",
       "      <td>11.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  SVM + SBERT + undersampled     79.30      86.89   79.30     81.66   \n",
       "\n",
       "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
       "0             3.58              3.57           3.58       3.63   \n",
       "\n",
       "   Time to Predict (ms)  \n",
       "0                 11.88  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"LR + SBERT + undersampled\"\n",
    "pipeline_bert_lr = Pipeline([\n",
    "    ('clf', LogisticRegression(  random_state=SEED)) \n",
    "    #('clf', LogisticRegression( class_weight=class_weights_dict, random_state=SEED)) \n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = pipeline_bert_lr\n",
    "param_grid = param_grid_lr\n",
    "X_train = X_train_bert_resampled\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_bert\n",
    "y_test = y_test_original\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict , y_lr_sbert= evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF + SBERT + undersampling: Training the model...\n",
      "Initial Training Time: 928.0000 ms\n",
      "\n",
      "RF + SBERT + undersampling: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters: {'clf__max_depth': None, 'clf__max_features': 'log2', 'clf__min_samples_split': 5, 'clf__n_estimators': 200}\n",
      "Best CV Score: 0.7026570452509995\n",
      "\n",
      "--- Evaluating Model: RF + SBERT + undersampling ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.6962, std=0.0408, 95% CI=(0.6695, 0.7228)\n",
      "All CV scores for accuracy: [0.78       0.72       0.7        0.68       0.71428571 0.67346939\n",
      " 0.69387755 0.67346939 0.71428571 0.6122449 ]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7017, std=0.0387, 95% CI=(0.6764, 0.7270)\n",
      "All CV scores for precision_weighted: [0.78044872 0.72       0.71701389 0.68115942 0.71921182 0.69202226\n",
      " 0.69394581 0.67930029 0.71428571 0.61986044]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.6962, std=0.0408, 95% CI=(0.6695, 0.7228)\n",
      "All CV scores for recall_weighted: [0.78       0.72       0.7        0.68       0.71428571 0.67346939\n",
      " 0.69387755 0.67346939 0.71428571 0.6122449 ]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.6931, std=0.0433, 95% CI=(0.6649, 0.7214)\n",
      "All CV scores for f1_weighted: [0.77991196 0.72       0.69400245 0.67948718 0.71188071 0.66333568\n",
      " 0.69362213 0.67183127 0.71428571 0.60295338]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 18.0190 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       366\n",
      "           1       0.41      0.69      0.51        64\n",
      "\n",
      "    accuracy                           0.81       430\n",
      "   macro avg       0.67      0.76      0.70       430\n",
      "weighted avg       0.86      0.81      0.83       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.8070 | bootstrap mean=0.8060, std=0.0191, 95% CI=(0.7674, 0.8419)\n",
      "precision_weighted: 0.8597 | bootstrap mean=0.8606, std=0.0168, 95% CI=(0.8279, 0.8914)\n",
      "recall_weighted: 0.8070 | bootstrap mean=0.8073, std=0.0190, 95% CI=(0.7698, 0.8419)\n",
      "f1_weighted: 0.8252 | bootstrap mean=0.8253, std=0.0169, 95% CI=(0.7929, 0.8577)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"RF + SBERT + undersampling\"\n",
    "pipeline_bert_rf = Pipeline([\n",
    "    ('clf', RandomForestClassifier(  random_state=SEED)) \n",
    "])\n",
    "\n",
    "pipeline = pipeline_bert_rf\n",
    "param_grid = param_grid_rf\n",
    "X_train = X_train_bert_resampled\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_bert\n",
    "y_test = y_test_original\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_rf_sb = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB + SBERT: Training the model...\n",
      "Initial Training Time: 521.9998 ms\n",
      "\n",
      "XGB + SBERT: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Parameters: {'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 500, 'clf__subsample': 0.8}\n",
      "Best CV Score: 0.6935314626272072\n",
      "\n",
      "--- Evaluating Model: XGB + SBERT ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.6902, std=0.0388, 95% CI=(0.6648, 0.7156)\n",
      "All CV scores for accuracy: [0.78       0.66       0.68       0.68       0.65306122 0.65306122\n",
      " 0.73469388 0.67346939 0.71428571 0.67346939]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.6965, std=0.0408, 95% CI=(0.6698, 0.7231)\n",
      "All CV scores for precision_weighted: [0.78044872 0.66025641 0.68472906 0.68115942 0.6530271  0.65825277\n",
      " 0.7569673  0.68614393 0.72108844 0.68290542]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.6902, std=0.0388, 95% CI=(0.6648, 0.7156)\n",
      "All CV scores for recall_weighted: [0.78       0.66       0.68       0.68       0.65306122 0.65306122\n",
      " 0.73469388 0.67346939 0.71428571 0.67346939]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.6878, std=0.0392, 95% CI=(0.6623, 0.7134)\n",
      "All CV scores for f1_weighted: [0.77991196 0.65986395 0.67793881 0.67948718 0.65277175 0.64866031\n",
      " 0.72998231 0.66934653 0.71285237 0.66763848]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 2.0111 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.86       366\n",
      "           1       0.37      0.72      0.49        64\n",
      "\n",
      "    accuracy                           0.77       430\n",
      "   macro avg       0.65      0.75      0.67       430\n",
      "weighted avg       0.86      0.77      0.80       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.7744 | bootstrap mean=0.7745, std=0.0202, 95% CI=(0.7349, 0.8140)\n",
      "precision_weighted: 0.8557 | bootstrap mean=0.8569, std=0.0177, 95% CI=(0.8213, 0.8907)\n",
      "recall_weighted: 0.7744 | bootstrap mean=0.7744, std=0.0205, 95% CI=(0.7326, 0.8163)\n",
      "f1_weighted: 0.8006 | bootstrap mean=0.8005, std=0.0176, 95% CI=(0.7660, 0.8342)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights_dict = dict(zip(class_labels, class_weights_array))\n",
    "\n",
    "# Extract the weight for the positive class (assuming label '1')\n",
    "# If your positive class has a different label, adjust accordingly\n",
    "positive_class_weight = class_weights_dict.get(1, 1) # Default to 1 if not found\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "# A common heuristic is the ratio of the number of negative instances to the number of positive instances\n",
    "negative_count = np.sum(y_train == 0)\n",
    "positive_count = np.sum(y_train == 1)\n",
    "scale_pos_weight_value = negative_count / positive_count if positive_count > 0 else 1\n",
    "\n",
    "model_name = \"XGB + SBERT\"\n",
    "pipeline_xgb = Pipeline([\n",
    "    #('clf', XGBClassifier(scale_pos_weight=scale_pos_weight_value, random_state=SEED)) \n",
    "    ('clf', XGBClassifier(random_state=SEED)) \n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "pipeline = pipeline_xgb\n",
    "param_grid = param_grid_xgb\n",
    "X_train = X_train_bert_resampled\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_bert\n",
    "y_test = y_test_original\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_xgb_sb  = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost + SBERT + undersampling: Training the model...\n",
      "Initial Training Time: 1963.1209 ms\n",
      "\n",
      "AdaBoost + SBERT + undersampling: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters: {'clf__estimator': DecisionTreeClassifier(max_depth=2), 'clf__learning_rate': 0.1, 'clf__n_estimators': 300}\n",
      "Best CV Score: 0.6887430697957014\n",
      "\n",
      "--- Evaluating Model: AdaBoost + SBERT + undersampling ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.6680, std=0.0508, 95% CI=(0.6348, 0.7012)\n",
      "All CV scores for accuracy: [0.66       0.62       0.68       0.72       0.67346939 0.59183673\n",
      " 0.7755102  0.6122449  0.67346939 0.67346939]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.6702, std=0.0535, 95% CI=(0.6352, 0.7051)\n",
      "All CV scores for precision_weighted: [0.66025641 0.62019231 0.68       0.72141707 0.67346939 0.5929627\n",
      " 0.78835327 0.6127551  0.67517576 0.67712878]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.6680, std=0.0508, 95% CI=(0.6348, 0.7012)\n",
      "All CV scores for recall_weighted: [0.66       0.62       0.68       0.72       0.67346939 0.59183673\n",
      " 0.7755102  0.6122449  0.67346939 0.67346939]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.6671, std=0.0508, 95% CI=(0.6339, 0.7003)\n",
      "All CV scores for f1_weighted: [0.65986395 0.61984794 0.68       0.71955128 0.67346939 0.58840102\n",
      " 0.77362769 0.6122449  0.67319728 0.67072081]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 122.0057 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84       366\n",
      "           1       0.34      0.75      0.47        64\n",
      "\n",
      "    accuracy                           0.75       430\n",
      "   macro avg       0.64      0.75      0.65       430\n",
      "weighted avg       0.86      0.75      0.78       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.7488 | bootstrap mean=0.7482, std=0.0204, 95% CI=(0.7093, 0.7884)\n",
      "precision_weighted: 0.8552 | bootstrap mean=0.8553, std=0.0174, 95% CI=(0.8215, 0.8886)\n",
      "recall_weighted: 0.7488 | bootstrap mean=0.7482, std=0.0208, 95% CI=(0.7070, 0.7884)\n",
      "f1_weighted: 0.7811 | bootstrap mean=0.7809, std=0.0174, 95% CI=(0.7466, 0.8144)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif # Example selector/scorer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_name = 'AdaBoost + SBERT + undersampling'\n",
    "\n",
    "# Define a pipeline with AdaBoost instead of LGBM\n",
    "pipeline_adaboost = Pipeline([\n",
    "    ('clf',  AdaBoostClassifier( random_state=SEED))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Set pipeline and param grid\n",
    "pipeline = pipeline_adaboost\n",
    "param_grid = param_grid_adaboost\n",
    "\n",
    "X_train = X_train_bert_resampled\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_bert\n",
    "y_test = y_test_original\n",
    "\n",
    "\n",
    "# Train the model\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\",\n",
    "\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_result, nfold_results, time_to_predict , y_pred_ad_sb = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time=train_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>cv_std_accuracy</th>\n",
       "      <th>cv_std_precision</th>\n",
       "      <th>cv_std_recall</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>Time to Predict (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM + SBERT + undersampled</td>\n",
       "      <td>79.30</td>\n",
       "      <td>86.89</td>\n",
       "      <td>79.30</td>\n",
       "      <td>81.66</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.63</td>\n",
       "      <td>11.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR + SBERT + undersampled</td>\n",
       "      <td>78.84</td>\n",
       "      <td>85.94</td>\n",
       "      <td>78.84</td>\n",
       "      <td>81.16</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF + SBERT + undersampling</td>\n",
       "      <td>80.70</td>\n",
       "      <td>85.97</td>\n",
       "      <td>80.70</td>\n",
       "      <td>82.52</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.33</td>\n",
       "      <td>18.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB + SBERT</td>\n",
       "      <td>77.44</td>\n",
       "      <td>85.57</td>\n",
       "      <td>77.44</td>\n",
       "      <td>80.06</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost + SBERT + undersampling</td>\n",
       "      <td>74.88</td>\n",
       "      <td>85.52</td>\n",
       "      <td>74.88</td>\n",
       "      <td>78.11</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.08</td>\n",
       "      <td>122.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0        SVM + SBERT + undersampled     79.30      86.89   79.30     81.66   \n",
       "1         LR + SBERT + undersampled     78.84      85.94   78.84     81.16   \n",
       "2        RF + SBERT + undersampling     80.70      85.97   80.70     82.52   \n",
       "3                       XGB + SBERT     77.44      85.57   77.44     80.06   \n",
       "4  AdaBoost + SBERT + undersampling     74.88      85.52   74.88     78.11   \n",
       "\n",
       "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
       "0             3.58              3.57           3.58       3.63   \n",
       "1             4.22              4.36           4.22       4.22   \n",
       "2             4.08              3.87           4.08       4.33   \n",
       "3             3.88              4.08           3.88       3.92   \n",
       "4             5.08              5.35           5.08       5.08   \n",
       "\n",
       "   Time to Predict (ms)  \n",
       "0                 11.88  \n",
       "1                  3.00  \n",
       "2                 18.02  \n",
       "3                  2.01  \n",
       "4                122.01  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'SVM + SBERT + undersampled',\n",
       "  'cv_scores': {'accuracy': array([0.76      , 0.64      , 0.7       , 0.72      , 0.69387755,\n",
       "          0.67346939, 0.75510204, 0.69387755, 0.67346939, 0.67346939]),\n",
       "   'precision_weighted': array([0.76683087, 0.64367816, 0.70292208, 0.72141707, 0.69394581,\n",
       "          0.68290542, 0.75510204, 0.69758813, 0.67346939, 0.67517576]),\n",
       "   'recall_weighted': array([0.76      , 0.64      , 0.7       , 0.72      , 0.69387755,\n",
       "          0.67346939, 0.75510204, 0.69387755, 0.67346939, 0.67346939]),\n",
       "   'f1_weighted': array([0.75845411, 0.63768116, 0.6989161 , 0.71955128, 0.69362213,\n",
       "          0.66763848, 0.75510204, 0.69311129, 0.67346939, 0.67319728])}},\n",
       " {'model': 'LR + SBERT + undersampled',\n",
       "  'cv_scores': {'accuracy': array([0.76      , 0.68      , 0.7       , 0.7       , 0.75510204,\n",
       "          0.71428571, 0.79591837, 0.65306122, 0.69387755, 0.67346939]),\n",
       "   'precision_weighted': array([0.76167472, 0.68115942, 0.70833333, 0.70032051, 0.75640761,\n",
       "          0.7265745 , 0.80466472, 0.65625644, 0.69445578, 0.67346939]),\n",
       "   'recall_weighted': array([0.76      , 0.68      , 0.7       , 0.7       , 0.75510204,\n",
       "          0.71428571, 0.79591837, 0.65306122, 0.69387755, 0.67346939]),\n",
       "   'f1_weighted': array([0.75961538, 0.67948718, 0.6969697 , 0.69987995, 0.75448775,\n",
       "          0.70918367, 0.79489455, 0.65219279, 0.69387755, 0.67346939])}},\n",
       " {'model': 'RF + SBERT + undersampling',\n",
       "  'cv_scores': {'accuracy': array([0.78      , 0.72      , 0.7       , 0.68      , 0.71428571,\n",
       "          0.67346939, 0.69387755, 0.67346939, 0.71428571, 0.6122449 ]),\n",
       "   'precision_weighted': array([0.78044872, 0.72      , 0.71701389, 0.68115942, 0.71921182,\n",
       "          0.69202226, 0.69394581, 0.67930029, 0.71428571, 0.61986044]),\n",
       "   'recall_weighted': array([0.78      , 0.72      , 0.7       , 0.68      , 0.71428571,\n",
       "          0.67346939, 0.69387755, 0.67346939, 0.71428571, 0.6122449 ]),\n",
       "   'f1_weighted': array([0.77991196, 0.72      , 0.69400245, 0.67948718, 0.71188071,\n",
       "          0.66333568, 0.69362213, 0.67183127, 0.71428571, 0.60295338])}},\n",
       " {'model': 'XGB + SBERT',\n",
       "  'cv_scores': {'accuracy': array([0.78      , 0.66      , 0.68      , 0.68      , 0.65306122,\n",
       "          0.65306122, 0.73469388, 0.67346939, 0.71428571, 0.67346939]),\n",
       "   'precision_weighted': array([0.78044872, 0.66025641, 0.68472906, 0.68115942, 0.6530271 ,\n",
       "          0.65825277, 0.7569673 , 0.68614393, 0.72108844, 0.68290542]),\n",
       "   'recall_weighted': array([0.78      , 0.66      , 0.68      , 0.68      , 0.65306122,\n",
       "          0.65306122, 0.73469388, 0.67346939, 0.71428571, 0.67346939]),\n",
       "   'f1_weighted': array([0.77991196, 0.65986395, 0.67793881, 0.67948718, 0.65277175,\n",
       "          0.64866031, 0.72998231, 0.66934653, 0.71285237, 0.66763848])}},\n",
       " {'model': 'AdaBoost + SBERT + undersampling',\n",
       "  'cv_scores': {'accuracy': array([0.66      , 0.62      , 0.68      , 0.72      , 0.67346939,\n",
       "          0.59183673, 0.7755102 , 0.6122449 , 0.67346939, 0.67346939]),\n",
       "   'precision_weighted': array([0.66025641, 0.62019231, 0.68      , 0.72141707, 0.67346939,\n",
       "          0.5929627 , 0.78835327, 0.6127551 , 0.67517576, 0.67712878]),\n",
       "   'recall_weighted': array([0.66      , 0.62      , 0.68      , 0.72      , 0.67346939,\n",
       "          0.59183673, 0.7755102 , 0.6122449 , 0.67346939, 0.67346939]),\n",
       "   'f1_weighted': array([0.65986395, 0.61984794, 0.68      , 0.71955128, 0.67346939,\n",
       "          0.58840102, 0.77362769, 0.6122449 , 0.67319728, 0.67072081])}}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in DataFrame: Index(['model', 'cv_scores'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert list of dictionaries to DataFrame\n",
    "nfold_results_df = pd.DataFrame(nfold_results)\n",
    "temp = nfold_results_df[nfold_results_df.model.str.contains(\"SBERT\") == True]\n",
    "# Print column names to verify\n",
    "print(\"Column names in DataFrame:\", nfold_results_df.columns)\n",
    "\n",
    "# Ensure correct column names\n",
    "if 'model' in temp.columns and 'Accuracy' in temp.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for model in temp['model'].unique():\n",
    "        # Extract accuracy scores (each value is a list)\n",
    "        model_scores = temp[temp['model'] == model]['accuracy'].explode().astype(float)\n",
    "        \n",
    "        # Plot individual accuracy scores across cross-validation folds\n",
    "        plt.plot(range(1, len(model_scores) + 1), model_scores, marker='.', linestyle='-', label=model)\n",
    "\n",
    "    plt.xlabel('Cross-validation Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Cross-validation Recall per Model')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_gridsearch_dir\\mlp_sbert_gridsearch_tuning\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Choice)\n",
      "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
      "dropout (Choice)\n",
      "{'default': 0.2, 'conditions': [], 'values': [0.2, 0.3, 0.4], 'ordered': True}\n",
      "Results summary\n",
      "Results in keras_tuner_gridsearch_dir\\mlp_sbert_gridsearch_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"f1_score\", direction=\"max\")\n",
      "\n",
      "Trial 0002 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "dropout: 0.4\n",
      "Score: 1.0\n",
      "\n",
      "Trial 0001 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "dropout: 0.3\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 265, in _run_and_update_trial\n",
      "    tuner_utils.convert_to_metrics_dict(\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 132, in convert_to_metrics_dict\n",
      "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 145, in convert_to_metrics_dict\n",
      "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 116, in _get_best_value_and_best_epoch_from_history\n",
      "    objective_value = objective.get_value(metrics)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\objective.py\", line 59, in get_value\n",
      "    return logs[self.name]\n",
      "           ~~~~^^^^^^^^^^^\n",
      "KeyError: 'f1'\n",
      "\n",
      "\n",
      "Trial 0000 summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "dropout: 0.2\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 265, in _run_and_update_trial\n",
      "    tuner_utils.convert_to_metrics_dict(\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 132, in convert_to_metrics_dict\n",
      "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 145, in convert_to_metrics_dict\n",
      "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 116, in _get_best_value_and_best_epoch_from_history\n",
      "    objective_value = objective.get_value(metrics)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\keras_tuner\\src\\engine\\objective.py\", line 59, in get_value\n",
      "    return logs[self.name]\n",
      "           ~~~~^^^^^^^^^^^\n",
      "KeyError: 'f1'\n",
      "\n",
      "\n",
      "Best Hyperparameters: {'units': 64, 'dropout': 0.4}\n",
      "Epoch 1/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0473 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.1177\n",
      "Epoch 2/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9923 - f1_score_weighted: 0.9892 - loss: 0.0441 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.1329\n",
      "Epoch 3/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9919 - f1_score_weighted: 0.9886 - loss: 0.0456 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.0939\n",
      "Epoch 4/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9977 - f1_score_weighted: 0.9969 - loss: 0.0466 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.0799\n",
      "Epoch 5/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0483 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.0726\n",
      "Epoch 6/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9923 - f1_score_weighted: 0.9892 - loss: 0.0489 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.1264\n",
      "Epoch 7/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9923 - f1_score_weighted: 0.9892 - loss: 0.0448 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.0955\n",
      "Epoch 8/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9982 - f1_score_weighted: 0.9975 - loss: 0.0453 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.2171\n",
      "Epoch 9/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0400 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.1723\n",
      "Epoch 10/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0456 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.0863\n",
      "Epoch 11/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9919 - f1_score_weighted: 0.9886 - loss: 0.0444 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.0828\n",
      "Epoch 12/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9919 - f1_score_weighted: 0.9886 - loss: 0.0466 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.2167\n",
      "Epoch 13/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0363 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.1203\n",
      "Epoch 14/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0419 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.1981\n",
      "Epoch 15/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9973 - f1_score_weighted: 0.9963 - loss: 0.0359 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.2195\n",
      "Epoch 16/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0367 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.2909\n",
      "Epoch 17/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9955 - f1_score_weighted: 0.9937 - loss: 0.0424 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.1369\n",
      "Epoch 18/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0376 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.2711\n",
      "Epoch 19/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9973 - f1_score_weighted: 0.9963 - loss: 0.0417 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.2903\n",
      "Epoch 20/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0375 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2086\n",
      "Epoch 21/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0391 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2398\n",
      "Epoch 22/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9973 - f1_score_weighted: 0.9964 - loss: 0.0349 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2976\n",
      "Epoch 23/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0367 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2617\n",
      "Epoch 24/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0385 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2667\n",
      "Epoch 25/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0299 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.3628\n",
      "Epoch 26/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0328 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2968\n",
      "Epoch 27/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0395 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.2613\n",
      "Epoch 28/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0370 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3553\n",
      "Epoch 29/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9911 - f1_score_weighted: 0.9873 - loss: 0.0353 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3103\n",
      "Epoch 30/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0367 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.4014\n",
      "Epoch 31/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9952 - f1_score_weighted: 0.9932 - loss: 0.0336 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3310\n",
      "Epoch 32/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9968 - f1_score_weighted: 0.9956 - loss: 0.0300 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3440\n",
      "Epoch 33/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0350 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3749\n",
      "Epoch 34/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0343 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3668\n",
      "Epoch 35/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0309 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.4091\n",
      "Epoch 36/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0353 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.3791\n",
      "Epoch 37/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0298 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3428\n",
      "Epoch 38/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0352 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.4630\n",
      "Epoch 39/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0296 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3362\n",
      "Epoch 40/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0298 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.3374\n",
      "Epoch 41/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0337 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.3226\n",
      "Epoch 42/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0263 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.4651\n",
      "Epoch 43/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9914 - f1_score_weighted: 0.9879 - loss: 0.0342 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.4009\n",
      "Epoch 44/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0258 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.4665\n",
      "Epoch 45/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9942 - f1_score_weighted: 0.9919 - loss: 0.0317 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.5419\n",
      "Epoch 46/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9927 - f1_score_weighted: 0.9898 - loss: 0.0287 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.3628\n",
      "Epoch 47/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0289 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.4504\n",
      "Epoch 48/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0321 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.4595\n",
      "Epoch 49/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0342 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.3622\n",
      "Epoch 50/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0249 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.5308\n",
      "Epoch 51/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0297 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.5355\n",
      "Epoch 52/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0282 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.4635\n",
      "Epoch 53/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0287 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.6180\n",
      "Epoch 54/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0236 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.5772\n",
      "Epoch 55/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9884 - f1_score_weighted: 0.9836 - loss: 0.0269 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.4925\n",
      "Epoch 56/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0236 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.5695\n",
      "Epoch 57/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0252 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.5896\n",
      "Epoch 58/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0177 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.6219\n",
      "Epoch 59/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9936 - f1_score_weighted: 0.9910 - loss: 0.0245 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.5554\n",
      "Epoch 60/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0233 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.6383\n",
      "Epoch 61/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0225 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.6849\n",
      "Epoch 62/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9898 - f1_score_weighted: 0.9855 - loss: 0.0287 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.3987\n",
      "Epoch 63/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0275 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.6083\n",
      "Epoch 64/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0229 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.6794\n",
      "Epoch 65/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0225 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.5310\n",
      "Epoch 66/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0202 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.6281\n",
      "Epoch 67/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0280 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.7282\n",
      "Epoch 68/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0214 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.8025\n",
      "Epoch 69/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0208 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.7392\n",
      "Epoch 70/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0253 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6153\n",
      "Epoch 71/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0227 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6298\n",
      "Epoch 72/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0264 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.8102\n",
      "Epoch 73/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0193 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.7992\n",
      "Epoch 74/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0192 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6105\n",
      "Epoch 75/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0213 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6755\n",
      "Epoch 76/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0199 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.7759\n",
      "Epoch 77/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9921 - loss: 0.0263 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6552\n",
      "Epoch 78/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0244 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.8325\n",
      "Epoch 79/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0259 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6304\n",
      "Epoch 80/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0188 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6821\n",
      "Epoch 81/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0183 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.8311\n",
      "Epoch 82/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9936 - f1_score_weighted: 0.9910 - loss: 0.0262 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6548\n",
      "Epoch 83/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0217 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6986\n",
      "Epoch 84/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0171 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7276\n",
      "Epoch 85/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0198 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7079\n",
      "Epoch 86/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0202 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7195\n",
      "Epoch 87/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9936 - f1_score_weighted: 0.9910 - loss: 0.0270 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.7902\n",
      "Epoch 88/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0242 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.9464\n",
      "Epoch 89/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9919 - f1_score_weighted: 0.9886 - loss: 0.0254 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6334\n",
      "Epoch 90/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0193 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6856\n",
      "Epoch 91/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0182 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 2.9970\n",
      "Epoch 92/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9975 - f1_score_weighted: 0.9965 - loss: 0.0182 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7453\n",
      "Epoch 93/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0166 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.6324\n",
      "Epoch 94/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0174 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8023\n",
      "Epoch 95/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0245 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.9191\n",
      "Epoch 96/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9892 - f1_score_weighted: 0.9844 - loss: 0.0255 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7260\n",
      "Epoch 97/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0216 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8155\n",
      "Epoch 98/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0145 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.8954\n",
      "Epoch 99/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0193 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8381\n",
      "Epoch 100/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0146 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7829\n",
      "Epoch 101/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0166 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8600\n",
      "Epoch 102/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0181 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8784\n",
      "Epoch 103/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0251 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8046\n",
      "Epoch 104/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0177 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.9648\n",
      "Epoch 105/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0161 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8659\n",
      "Epoch 106/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0232 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7908\n",
      "Epoch 107/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0171 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.7369\n",
      "Epoch 108/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0168 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.8889\n",
      "Epoch 109/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0215 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.9114\n",
      "Epoch 110/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0208 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8134\n",
      "Epoch 111/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0138 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9144\n",
      "Epoch 112/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9898 - f1_score_weighted: 0.9855 - loss: 0.0211 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8128\n",
      "Epoch 113/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0177 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8004\n",
      "Epoch 114/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0166 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.9971\n",
      "Epoch 115/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0137 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.0188\n",
      "Epoch 116/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0201 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9358\n",
      "Epoch 117/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0186 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8668\n",
      "Epoch 118/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0224 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.9461\n",
      "Epoch 119/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0148 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9286\n",
      "Epoch 120/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0147 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 2.9697\n",
      "Epoch 121/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0150 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9727\n",
      "Epoch 122/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0168 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9021\n",
      "Epoch 123/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0159 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9631\n",
      "Epoch 124/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0171 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9506\n",
      "Epoch 125/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0197 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8196\n",
      "Epoch 126/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0199 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8933\n",
      "Epoch 127/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0170 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9948\n",
      "Epoch 128/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0147 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.8614\n",
      "Epoch 129/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0162 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0063\n",
      "Epoch 130/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0211 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1041\n",
      "Epoch 131/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0159 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0063\n",
      "Epoch 132/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0132 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0909\n",
      "Epoch 133/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0130 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0680\n",
      "Epoch 134/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0124 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0725\n",
      "Epoch 135/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0168 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0691\n",
      "Epoch 136/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0136 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9496\n",
      "Epoch 137/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0121 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0818\n",
      "Epoch 138/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0120 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2062\n",
      "Epoch 139/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0136 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9988\n",
      "Epoch 140/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0119 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9035\n",
      "Epoch 141/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0196 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0934\n",
      "Epoch 142/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0184 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0967\n",
      "Epoch 143/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0140 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1309\n",
      "Epoch 144/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0136 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2122\n",
      "Epoch 145/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0137 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 2.9668\n",
      "Epoch 146/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0120 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0235\n",
      "Epoch 147/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0148 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.1933\n",
      "Epoch 148/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0158 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0546\n",
      "Epoch 149/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0153 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1486\n",
      "Epoch 150/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0142 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1080\n",
      "Epoch 151/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0126 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0104\n",
      "Epoch 152/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0133 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0925\n",
      "Epoch 153/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0095 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1608\n",
      "Epoch 154/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0146 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1687\n",
      "Epoch 155/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0113 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1707\n",
      "Epoch 156/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0122 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2205\n",
      "Epoch 157/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0100 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1837\n",
      "Epoch 158/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0121 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2062\n",
      "Epoch 159/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0192 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1649\n",
      "Epoch 160/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0133 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2088\n",
      "Epoch 161/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0133 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.3194\n",
      "Epoch 162/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0082 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2154\n",
      "Epoch 163/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0139 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2391\n",
      "Epoch 164/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0108 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.3638\n",
      "Epoch 165/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0122 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1413\n",
      "Epoch 166/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0127 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0631\n",
      "Epoch 167/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0124 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1156\n",
      "Epoch 168/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0103 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2270\n",
      "Epoch 169/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0111 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3614\n",
      "Epoch 170/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0149 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1491\n",
      "Epoch 171/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0129 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1064\n",
      "Epoch 172/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0145 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2166\n",
      "Epoch 173/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0144 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1895\n",
      "Epoch 174/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0128 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.2568\n",
      "Epoch 175/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0137 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2693\n",
      "Epoch 176/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0077 - val_accuracy: 0.4747 - val_f1_score_weighted: 0.6438 - val_loss: 3.2914\n",
      "Epoch 177/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9919 - f1_score_weighted: 0.9886 - loss: 0.0148 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2173\n",
      "Epoch 178/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0093 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1004\n",
      "Epoch 179/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0158 - val_accuracy: 0.4747 - val_f1_score_weighted: 0.6438 - val_loss: 3.2874\n",
      "Epoch 180/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0082 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2731\n",
      "Epoch 181/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0122 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2109\n",
      "Epoch 182/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0120 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2869\n",
      "Epoch 183/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0129 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3307\n",
      "Epoch 184/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0141 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0973\n",
      "Epoch 185/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0128 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2686\n",
      "Epoch 186/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0122 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3555\n",
      "Epoch 187/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0118 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0730\n",
      "Epoch 188/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0122 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.0261\n",
      "Epoch 189/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0105 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3373\n",
      "Epoch 190/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0132 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2533\n",
      "Epoch 191/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0183 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2756\n",
      "Epoch 192/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0084 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3124\n",
      "Epoch 193/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0117 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.2845\n",
      "Epoch 194/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0095 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3158\n",
      "Epoch 195/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0089 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.4079\n",
      "Epoch 196/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0105 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3714\n",
      "Epoch 197/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0114 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1531\n",
      "Epoch 198/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0117 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3137\n",
      "Epoch 199/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0095 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3479\n",
      "Epoch 200/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0108 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2947\n",
      "Epoch 201/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0132 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3673\n",
      "Epoch 202/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0124 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.4019\n",
      "Epoch 203/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0074 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3270\n",
      "Epoch 204/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0134 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.3990\n",
      "Epoch 205/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0119 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3852\n",
      "Epoch 206/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0077 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3077\n",
      "Epoch 207/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0094 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2634\n",
      "Epoch 208/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0110 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4083\n",
      "Epoch 209/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0127 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.4723\n",
      "Epoch 210/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0062 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.5110\n",
      "Epoch 211/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9962 - f1_score_weighted: 0.9947 - loss: 0.0117 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3025\n",
      "Epoch 212/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0105 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3574\n",
      "Epoch 213/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0096 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.4617\n",
      "Epoch 214/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0092 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.5140\n",
      "Epoch 215/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0084 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.5161\n",
      "Epoch 216/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0149 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4068\n",
      "Epoch 217/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0113 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4528\n",
      "Epoch 218/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0104 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4380\n",
      "Epoch 219/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0091 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3828\n",
      "Epoch 220/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0102 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3875\n",
      "Epoch 221/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0118 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4139\n",
      "Epoch 222/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0133 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.1807\n",
      "Epoch 223/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0108 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.2276\n",
      "Epoch 224/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0080 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4704\n",
      "Epoch 225/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0129 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4819\n",
      "Epoch 226/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0075 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4947\n",
      "Epoch 227/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0124 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5569\n",
      "Epoch 228/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0088 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4909\n",
      "Epoch 229/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0112 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.5541\n",
      "Epoch 230/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0085 - val_accuracy: 0.4747 - val_f1_score_weighted: 0.6438 - val_loss: 3.6495\n",
      "Epoch 231/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0085 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4040\n",
      "Epoch 232/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0081 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.4865\n",
      "Epoch 233/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0129 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.5038\n",
      "Epoch 234/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0069 - val_accuracy: 0.4747 - val_f1_score_weighted: 0.6438 - val_loss: 3.6089\n",
      "Epoch 235/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0076 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5225\n",
      "Epoch 236/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0101 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4538\n",
      "Epoch 237/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0111 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3845\n",
      "Epoch 238/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0102 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3735\n",
      "Epoch 239/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0120 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.6196\n",
      "Epoch 240/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0083 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.6633\n",
      "Epoch 241/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0128 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5774\n",
      "Epoch 242/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9878 - f1_score_weighted: 0.9826 - loss: 0.0151 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5897\n",
      "Epoch 243/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0100 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4541\n",
      "Epoch 244/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0079 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4121\n",
      "Epoch 245/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0083 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6380\n",
      "Epoch 246/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0087 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6171\n",
      "Epoch 247/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0098 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.3769\n",
      "Epoch 248/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0100 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6003\n",
      "Epoch 249/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0072 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.6629\n",
      "Epoch 250/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0137 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5092\n",
      "Epoch 251/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0080 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5497\n",
      "Epoch 252/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0087 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.6507\n",
      "Epoch 253/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0094 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.6234\n",
      "Epoch 254/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0128 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5584\n",
      "Epoch 255/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0093 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6054\n",
      "Epoch 256/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0065 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.7204\n",
      "Epoch 257/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0067 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.7137\n",
      "Epoch 258/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0115 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6384\n",
      "Epoch 259/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0090 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.4854\n",
      "Epoch 260/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0122 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.6449\n",
      "Epoch 261/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0093 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.7753\n",
      "Epoch 262/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0108 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.8266\n",
      "Epoch 263/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0073 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6721\n",
      "Epoch 264/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0076 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6106\n",
      "Epoch 265/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0063 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5179\n",
      "Epoch 266/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0105 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5883\n",
      "Epoch 267/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0081 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.6542\n",
      "Epoch 268/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0113 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.6791\n",
      "Epoch 269/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0068 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.7917\n",
      "Epoch 270/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0088 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.7587\n",
      "Epoch 271/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0072 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.6738\n",
      "Epoch 272/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0103 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6453\n",
      "Epoch 273/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0106 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.7162\n",
      "Epoch 274/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0063 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6974\n",
      "Epoch 275/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0085 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5808\n",
      "Epoch 276/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0085 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6101\n",
      "Epoch 277/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0084 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6544\n",
      "Epoch 278/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0075 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6936\n",
      "Epoch 279/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0112 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5537\n",
      "Epoch 280/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0135 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5660\n",
      "Epoch 281/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0069 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6407\n",
      "Epoch 282/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0072 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.7741\n",
      "Epoch 283/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0099 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6804\n",
      "Epoch 284/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0093 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.6617\n",
      "Epoch 285/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0116 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.7914\n",
      "Epoch 286/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0059 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7600\n",
      "Epoch 287/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0075 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7587\n",
      "Epoch 288/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0054 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7443\n",
      "Epoch 289/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0129 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.8067\n",
      "Epoch 290/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0076 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.8644\n",
      "Epoch 291/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0151 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.5798\n",
      "Epoch 292/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0087 - val_accuracy: 0.4949 - val_f1_score_weighted: 0.6622 - val_loss: 3.7618\n",
      "Epoch 293/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0075 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.8736\n",
      "Epoch 294/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0090 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.8623\n",
      "Epoch 295/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0107 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7522\n",
      "Epoch 296/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - f1_score_weighted: 1.0000 - loss: 0.0066 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7662\n",
      "Epoch 297/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9946 - f1_score_weighted: 0.9923 - loss: 0.0084 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.8524\n",
      "Epoch 298/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0068 - val_accuracy: 0.4848 - val_f1_score_weighted: 0.6531 - val_loss: 3.9634\n",
      "Epoch 299/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9987 - f1_score_weighted: 0.9982 - loss: 0.0063 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7154\n",
      "Epoch 300/300\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9932 - f1_score_weighted: 0.9905 - loss: 0.0086 - val_accuracy: 0.5051 - val_f1_score_weighted: 0.6711 - val_loss: 3.7563\n",
      "Initial Training Time: 52692.0478 ms\n",
      "Initial Test Time: 52692.0478 ms\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results with Tuned Model (Keras Tuner GridSearch):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>cv_std_accuracy</th>\n",
       "      <th>cv_std_precision</th>\n",
       "      <th>cv_std_recall</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>Time to Predict (ms)</th>\n",
       "      <th>Time to predict</th>\n",
       "      <th>Best Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM + SBERT + undersampled</td>\n",
       "      <td>79.30</td>\n",
       "      <td>86.89</td>\n",
       "      <td>79.30</td>\n",
       "      <td>81.66</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.63</td>\n",
       "      <td>11.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR + SBERT + undersampled</td>\n",
       "      <td>78.84</td>\n",
       "      <td>85.94</td>\n",
       "      <td>78.84</td>\n",
       "      <td>81.16</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF + SBERT + undersampling</td>\n",
       "      <td>80.70</td>\n",
       "      <td>85.97</td>\n",
       "      <td>80.70</td>\n",
       "      <td>82.52</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.33</td>\n",
       "      <td>18.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB + SBERT</td>\n",
       "      <td>77.44</td>\n",
       "      <td>85.57</td>\n",
       "      <td>77.44</td>\n",
       "      <td>80.06</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost + SBERT + undersampling</td>\n",
       "      <td>74.88</td>\n",
       "      <td>85.52</td>\n",
       "      <td>74.88</td>\n",
       "      <td>78.11</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.08</td>\n",
       "      <td>122.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP + SBERT + undersampling</td>\n",
       "      <td>75.58</td>\n",
       "      <td>83.43</td>\n",
       "      <td>75.58</td>\n",
       "      <td>78.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.61</td>\n",
       "      <td>{'units': 64, 'dropout': 0.4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP + SBERT + undersampling</td>\n",
       "      <td>75.58</td>\n",
       "      <td>83.43</td>\n",
       "      <td>75.58</td>\n",
       "      <td>78.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.77</td>\n",
       "      <td>{'units': 64, 'dropout': 0.4}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0        SVM + SBERT + undersampled     79.30      86.89   79.30     81.66   \n",
       "1         LR + SBERT + undersampled     78.84      85.94   78.84     81.16   \n",
       "2        RF + SBERT + undersampling     80.70      85.97   80.70     82.52   \n",
       "3                       XGB + SBERT     77.44      85.57   77.44     80.06   \n",
       "4  AdaBoost + SBERT + undersampling     74.88      85.52   74.88     78.11   \n",
       "5       MLP + SBERT + undersampling     75.58      83.43   75.58     78.31   \n",
       "6       MLP + SBERT + undersampling     75.58      83.43   75.58     78.31   \n",
       "\n",
       "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
       "0             3.58              3.57           3.58       3.63   \n",
       "1             4.22              4.36           4.22       4.22   \n",
       "2             4.08              3.87           4.08       4.33   \n",
       "3             3.88              4.08           3.88       3.92   \n",
       "4             5.08              5.35           5.08       5.08   \n",
       "5              NaN               NaN            NaN        NaN   \n",
       "6              NaN               NaN            NaN        NaN   \n",
       "\n",
       "   Time to Predict (ms)  Time to predict           Best Hyperparameters  \n",
       "0                 11.88              NaN                            NaN  \n",
       "1                  3.00              NaN                            NaN  \n",
       "2                 18.02              NaN                            NaN  \n",
       "3                  2.01              NaN                            NaN  \n",
       "4                122.01              NaN                            NaN  \n",
       "5                   NaN           272.61  {'units': 64, 'dropout': 0.4}  \n",
       "6                   NaN           136.77  {'units': 64, 'dropout': 0.4}  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MLP + SBERT + undersampling\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from kerastuner.tuners import GridSearch  # Import GridSearch tuner\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from keras_tuner import GridSearch, Objective\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test, and test_result are already defined\n",
    "\n",
    "X_train = X_train_bert_resampled\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_bert\n",
    "y_test = y_test_original\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_grid_mlp = {\n",
    "    'units_dense1': [128, 256],\n",
    "    'activation1': ['relu', 'tanh'],\n",
    "    'dropout_rate': [0.2, 0.3],\n",
    "    'units_dense2': [64, 128],\n",
    "    'activation2': ['relu'],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "}\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='min',\n",
    "    patience=300,\n",
    "    restore_best_weights=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "tuner = GridSearch(\n",
    "    hypermodel=build_mlp,\n",
    "    objective=Objective('f1_score', direction='max'),\n",
    "    directory=\"keras_tuner_gridsearch_dir\",\n",
    "    project_name=\"mlp_sbert_gridsearch_tuning\",\n",
    "    seed=SEED,\n",
    "    executions_per_trial=5,\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=300,\n",
    "             batch_size=64,\n",
    "             validation_split=0.2,\n",
    "             callbacks=[early_stop],    \n",
    "             verbose=1,\n",
    "             \n",
    "\n",
    ")\n",
    "\n",
    "# Print the search space summary (will reflect the grid)\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Print the results of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\\nBest Hyperparameters: {best_hps.values}\")\n",
    "\n",
    "# Build the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    "    \n",
    "\n",
    ")\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "print(f\"Initial Training Time: {train_time:.4f} ms\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Initial Test Time: {train_time:.4f} ms\")\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "\n",
    "y_pred_mlp_sb = (y_pred_probs > 0.5).astype(int).ravel()\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "y_pred_mlp_sb = (y_pred_probs > 0.5).astype(int).ravel()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title='Confusion Matrix', cmap='Blues'):\n",
    "    \"\"\"Plots the confusion matrix with percentages.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=labels)\n",
    "    disp.plot(cmap=cmap, values_format='.2f')\n",
    "    plt.title(f'{title} with Percentages')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_mlp_sb,\n",
    "                        labels=['Negative', 'Positive'],\n",
    "                        title=f'{model_name}',\n",
    "                        cmap='Blues')\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_mlp_sb)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_mlp_sb, average='weighted', zero_division=0)\n",
    "\n",
    "results = {\n",
    "    'Model': model_name,\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([results])], ignore_index=True)\n",
    "\n",
    "print(\"\\nTest Results with Tuned Model (Keras Tuner GridSearch):\")\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_bars(\n",
    "    df,\n",
    "    model_col='Model',\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)'\n",
    "):\n",
    "    labels = df[model_col].tolist()\n",
    "    metric1 = df[metric1_col].tolist()\n",
    "    metric2 = df[metric2_col].tolist()\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    width = 0.50  # Aumentei a largura das barras\n",
    "    gap = 0.40    # Aumentei o espa√ßo entre os grupos de barras\n",
    "    x_spaced = x * (1 + gap)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))  \n",
    "    rects1 = ax.bar(x_spaced - width/2, metric1, width, label=name_metric1)\n",
    "    rects2 = ax.bar(x_spaced + width/2, metric2, width, label=name_metric2)\n",
    "\n",
    "    def add_labels(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{height:.2f}',\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 5),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=10)\n",
    "\n",
    "    add_labels(rects1)\n",
    "    add_labels(rects2)\n",
    "\n",
    "    ax.set_ylabel('Score (%)', fontsize=12)\n",
    "    ax.set_title(f'Model Comparison: {name_metric1} vs {name_metric2}', fontsize=16)\n",
    "    ax.set_xticks(x_spaced)\n",
    "    ax.set_xticklabels(labels, rotation=45, fontsize=12, ha='right')\n",
    "\n",
    "    ax.legend(title='Metrics', loc='lower left', fontsize=11, title_fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     65\u001b[39m     model.compile(\n\u001b[32m     66\u001b[39m         optimizer=tf.keras.optimizers.Adam(hp.Float(\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-4\u001b[39m, \u001b[32m1e-2\u001b[39m, sampling=\u001b[33m'\u001b[39m\u001b[33mlog\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m     67\u001b[39m         loss=loss_fn,\n\u001b[32m     68\u001b[39m         metrics=metrics\n\u001b[32m     69\u001b[39m     )\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m sbert_embedding_dim = \u001b[43mX_train_resampled\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     74\u001b[39m hp_bilstm_attn = HyperParameters()\n\u001b[32m     75\u001b[39m hp_bilstm_attn.Int(\u001b[33m'\u001b[39m\u001b[33mlstm_units\u001b[39m\u001b[33m'\u001b[39m, min_value=\u001b[32m32\u001b[39m, max_value=\u001b[32m128\u001b[39m, step=\u001b[32m32\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Dropout, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner import HyperParameters, Objective, GridSearch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "is_binary = 2\n",
    "model_name = 'BiLSTM + Attention + SBERT'\n",
    "# Use the specified variables\n",
    "X_train = X_train_bert_resampled\n",
    "X_test = X_test_bert\n",
    "y_train = y_train_resampled\n",
    "y_test = y_test_original\n",
    "num_classes_bert = 2\n",
    "is_binary_bert = True\n",
    "\n",
    "def build_bilstm_attention_sbert(hp, sbert_embedding_dim, num_classes, is_binary):\n",
    "    input_layer = Input(shape=(sbert_embedding_dim,), name='sbert_input')\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1))(input_layer)  # Expand dims for LSTM\n",
    "\n",
    "    # BiLSTM Layer\n",
    "    lstm_units = hp.Int('lstm_units', 32, 128, step=32)\n",
    "    x = Bidirectional(LSTM(units=lstm_units, return_sequences=True, dropout=hp.Float('lstm_dropout', 0.2, 0.5, step=0.1)))(x)\n",
    "\n",
    "    # Attention Layer\n",
    "    class AttentionLayer(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
    "                                     initializer='random_normal', trainable=True)\n",
    "            super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            scores = tf.nn.softmax(tf.squeeze(tf.matmul(inputs, self.W), axis=-1), axis=1)\n",
    "            scores_expanded = tf.expand_dims(scores, axis=-1)\n",
    "            context_vector = tf.reduce_sum(inputs * scores_expanded, axis=1)\n",
    "            return context_vector\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return (input_shape[0], input_shape[-1])\n",
    "\n",
    "    attention_output = AttentionLayer()(x)\n",
    "\n",
    "    # Dense Layers\n",
    "    intermediate_units = hp.Int('dense_units', 64, 256, step=64)\n",
    "    x = Dense(intermediate_units, activation='relu')(attention_output)\n",
    "    x = Dropout(hp.Float('dropout_rate', 0.2, 0.5, step=0.1))(x)\n",
    "\n",
    "    # Output Layer\n",
    "    if is_binary:\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "        loss_fn = 'binary_crossentropy'\n",
    "        metrics = ['accuracy', F1Score(name='f1_score')]\n",
    "    else:\n",
    "        output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "        loss_fn = 'categorical_crossentropy'\n",
    "        metrics = ['accuracy', F1Score(name='f1_score')]\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss=loss_fn,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model\n",
    "\n",
    "sbert_embedding_dim = X_train_resampled.shape[1]\n",
    "\n",
    "hp_bilstm_attn = HyperParameters()\n",
    "hp_bilstm_attn.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "hp_bilstm_attn.Float('lstm_dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp_bilstm_attn.Int('dense_units', min_value=64, max_value=256, step=64)\n",
    "hp_bilstm_attn.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp_bilstm_attn.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "early_stop = EarlyStopping(monitor=Objective(\"accuracy\", direction=\"max\"), patience=100, restore_best_weights=True)\n",
    "\n",
    "tuner_bilstm_attn = GridSearch(\n",
    "    lambda hp: build_bilstm_attention_sbert(hp, sbert_embedding_dim, num_classes_bert, is_binary_bert),\n",
    "    objective=Objective(\"f1\", direction=\"max\"),\n",
    "    max_trials=5,  # Adjust as needed\n",
    "    directory='bilstm_attn_sbert_tune',\n",
    "    project_name='bilstm_attn_sbert',\n",
    "    overwrite=True,\n",
    "    hyperparameters=hp_bilstm_attn,\n",
    "    executions_per_trial=1 # Consider increasing for more robust results\n",
    ")\n",
    "\n",
    "print(\"\\nPerforming Grid Search for BiLSTM with Attention and SBERT...\")\n",
    "tuner_bilstm_attn.search(X_train, y_train,\n",
    "                         epochs=100,  # Adjust as needed\n",
    "                         validation_split=0.1,\n",
    "                         #callbacks=[early_stop],\n",
    "                         verbose=1)\n",
    "print(\"Grid Search Finished.\")\n",
    "\n",
    "best_hps_bilstm_attn = tuner_bilstm_attn.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters for BiLSTM with Attention and SBERT:\")\n",
    "print(best_hps_bilstm_attn.values)\n",
    "\n",
    "best_model_bilstm_attn = tuner_bilstm_attn.get_best_models(num_models=1)[0]\n",
    "best_model_bilstm_attn.summary()\n",
    "\n",
    "print(\"\\nEvaluating the Best BiLSTM with Attention and SBERT Model on the Test Set...\")\n",
    "loss_bilstm_attn, acc_bilstm_attn, f1_bilstm_attn = best_model_bilstm_attn.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss_bilstm_attn:.4f}\")\n",
    "print(f\"Accuracy: {acc_bilstm_attn:.4f}\")\n",
    "print(f\"F1 Score: {f1_bilstm_attn:.4f}\")\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Initial train time: {train_time:.4f} ms\")\n",
    "best_model_bilstm_attn.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "\n",
    "\n",
    "# Predict\n",
    "start_time = time.time()\n",
    "print(f\"Initial predict Time: {train_time:.4f} ms\")\n",
    "y_pred_probs_sbert = best_model_bilstm_attn.predict(X_test_bert)\n",
    "y_pred_sbert = (y_pred_probs_sbert > 0.5).astype(int).flatten() if is_binary else np.argmax(y_pred_probs_sbert, axis=1)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "# Calculate metrics\n",
    "prec_sbert, rec_sbert, f1_sbert, _ = precision_recall_fscore_support(\n",
    "    y_test_bert, y_pred_sbert, average='weighted', zero_division=0)\n",
    "\n",
    "# Save results\n",
    "best_results_sbert = {\n",
    "    'Model': 'BiLSTM + SBERT',\n",
    "    \"Accuracy\": round(acc_bilstm_attn * 100, 4),\n",
    "    \"Precision\": round(prec_sbert * 100, 4),\n",
    "    \"Recall\": round(rec_sbert * 100, 4),\n",
    "    \"F1 Score\": round(f1_sbert * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    \"Train time\": train_time,\n",
    "    'Best Hyperparameters': best_hps_bilstm_attn.values\n",
    "}\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([best_results_sbert])], ignore_index=True)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_binary = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Recall\n",
    "plot_comparison_bars(\n",
    "    df=test_result[test_result.Model.str.contains(\"BERT\")].sort_values(by=['Recall','Accuracy'] ),\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset for Glove\n",
    "glove = load_glove(r\"D:\\Users\\Jaque\\Downloads\\glove.6B.300d.txt\")  # or 300d\n",
    "\n",
    "model = GloveVectorizer(glove=glove, dim=300) \n",
    "original_indices = np.arange(len(df))\n",
    "X_resampled_GL = model.encode(X_train_resampled, show_progress_bar=True)\n",
    "X_test_GL = model.encode(X_test_original, show_progress_bar=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM + GLOVE: Training the model...\n",
      "Initial Training Time: 191.0014 ms\n",
      "\n",
      "SVM + GLOVE: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best Parameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__degree': 2, 'clf__gamma': 'scale', 'clf__kernel': 'linear', 'clf__max_iter': 1000}\n",
      "Best CV Score: 0.7463098221744838\n",
      "\n",
      "--- Evaluating Model: SVM + GLOVE ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7326, std=0.0503, 95% CI=(0.6997, 0.7655)\n",
      "All CV scores for accuracy: [0.68       0.8        0.82       0.74       0.75510204 0.69387755\n",
      " 0.65306122 0.69387755 0.75510204 0.73469388]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7446, std=0.0539, 95% CI=(0.7094, 0.7799)\n",
      "All CV scores for precision_weighted: [0.68       0.80788177 0.82051282 0.74350649 0.76129486 0.74040642\n",
      " 0.65360544 0.69394581 0.80752301 0.73760933]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7326, std=0.0503, 95% CI=(0.6997, 0.7655)\n",
      "All CV scores for recall_weighted: [0.68       0.8        0.82       0.74       0.75510204 0.69387755\n",
      " 0.65306122 0.69387755 0.75510204 0.73469388]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7292, std=0.0513, 95% CI=(0.6957, 0.7628)\n",
      "All CV scores for f1_weighted: [0.68       0.79871176 0.81992797 0.73906062 0.75304061 0.67597407\n",
      " 0.65306122 0.69362213 0.74560169 0.733359  ]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 12.0006 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       366\n",
      "           1       0.44      0.69      0.54        64\n",
      "\n",
      "    accuracy                           0.82       430\n",
      "   macro avg       0.69      0.77      0.71       430\n",
      "weighted avg       0.87      0.82      0.84       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.8233 | bootstrap mean=0.8241, std=0.0182, 95% CI=(0.7884, 0.8605)\n",
      "precision_weighted: 0.8651 | bootstrap mean=0.8657, std=0.0169, 95% CI=(0.8314, 0.8982)\n",
      "recall_weighted: 0.8233 | bootstrap mean=0.8241, std=0.0183, 95% CI=(0.7860, 0.8581)\n",
      "f1_weighted: 0.8381 | bootstrap mean=0.8376, std=0.0168, 95% CI=(0.8047, 0.8705)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"SVM + GLOVE\"\n",
    "\n",
    "\n",
    "pipeline_glove_svm = Pipeline([\n",
    "    ('clf', SVC(probability=True, random_state=SEED))\n",
    "])\n",
    "pipeline = pipeline_glove_svm\n",
    "param_grid = param_grid_svm \n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test_original\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict , y_pred_glove_svm= evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR + GLOVE undersampled: Training the model...\n",
      "Initial Training Time: 14.9946 ms\n",
      "\n",
      "LR + GLOVE undersampled: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Parameters: {'clf__C': 10, 'clf__max_iter': 50, 'clf__penalty': 'l2', 'clf__solver': 'saga'}\n",
      "Best CV Score: 0.7594499282460847\n",
      "\n",
      "--- Evaluating Model: LR + GLOVE undersampled ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7407, std=0.0457, 95% CI=(0.7108, 0.7706)\n",
      "All CV scores for accuracy: [0.72       0.82       0.8        0.7        0.75510204 0.73469388\n",
      " 0.65306122 0.71428571 0.75510204 0.75510204]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7498, std=0.0508, 95% CI=(0.7166, 0.7830)\n",
      "All CV scores for precision_weighted: [0.72       0.82467532 0.80788177 0.70032051 0.75640761 0.75412665\n",
      " 0.65625644 0.71428571 0.80752301 0.75640761]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7407, std=0.0457, 95% CI=(0.7108, 0.7706)\n",
      "All CV scores for recall_weighted: [0.72       0.82       0.8        0.7        0.75510204 0.73469388\n",
      " 0.65306122 0.71428571 0.75510204 0.75510204]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7387, std=0.0455, 95% CI=(0.7090, 0.7685)\n",
      "All CV scores for f1_weighted: [0.72       0.81934966 0.79871176 0.69987995 0.75448775 0.72833652\n",
      " 0.65219279 0.71428571 0.74560169 0.75448775]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 3.9997 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87       366\n",
      "           1       0.39      0.72      0.51        64\n",
      "\n",
      "    accuracy                           0.79       430\n",
      "   macro avg       0.67      0.76      0.69       430\n",
      "weighted avg       0.86      0.79      0.82       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.7930 | bootstrap mean=0.7927, std=0.0199, 95% CI=(0.7535, 0.8302)\n",
      "precision_weighted: 0.8607 | bootstrap mean=0.8611, std=0.0170, 95% CI=(0.8266, 0.8940)\n",
      "recall_weighted: 0.7930 | bootstrap mean=0.7930, std=0.0195, 95% CI=(0.7535, 0.8280)\n",
      "f1_weighted: 0.8152 | bootstrap mean=0.8149, std=0.0169, 95% CI=(0.7804, 0.8460)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"LR + GLOVE undersampled\"\n",
    "pipeline_glove_lr= Pipeline([\n",
    "    ('clf', LogisticRegression(  random_state=SEED)) \n",
    "])\n",
    "\n",
    "pipeline = pipeline_glove_lr\n",
    "param_grid = param_grid_lr\n",
    "\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test\n",
    "\n",
    "\n",
    "train_time, best_model, grid_search = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_lr_gl = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB + GLOVE undersampled: Training the model...\n",
      "Initial Training Time: 462.3017 ms\n",
      "\n",
      "XGB + GLOVE undersampled: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Parameters: {'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 500, 'clf__subsample': 0.8}\n",
      "Best CV Score: 0.7453416327382817\n",
      "\n",
      "--- Evaluating Model: XGB + GLOVE undersampled ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7225, std=0.0521, 95% CI=(0.6884, 0.7565)\n",
      "All CV scores for accuracy: [0.66       0.76       0.78       0.78       0.71428571 0.71428571\n",
      " 0.75510204 0.6122449  0.75510204 0.69387755]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7264, std=0.0535, 95% CI=(0.6914, 0.7613)\n",
      "All CV scores for precision_weighted: [0.66025641 0.76683087 0.78044872 0.78044872 0.71524772 0.7265745\n",
      " 0.76287658 0.61210839 0.76287658 0.69606414]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7225, std=0.0521, 95% CI=(0.6884, 0.7565)\n",
      "All CV scores for recall_weighted: [0.66       0.76       0.78       0.78       0.71428571 0.71428571\n",
      " 0.75510204 0.6122449  0.75510204 0.69387755]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7213, std=0.0521, 95% CI=(0.6872, 0.7553)\n",
      "All CV scores for f1_weighted: [0.65986395 0.75845411 0.77991196 0.77991196 0.71356904 0.70918367\n",
      " 0.75387346 0.61192136 0.75387346 0.69233731]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 4.0007 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.86       366\n",
      "           1       0.38      0.69      0.49        64\n",
      "\n",
      "    accuracy                           0.79       430\n",
      "   macro avg       0.66      0.75      0.68       430\n",
      "weighted avg       0.85      0.79      0.81       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.7860 | bootstrap mean=0.7865, std=0.0195, 95% CI=(0.7488, 0.8233)\n",
      "precision_weighted: 0.8534 | bootstrap mean=0.8540, std=0.0183, 95% CI=(0.8173, 0.8880)\n",
      "recall_weighted: 0.7860 | bootstrap mean=0.7859, std=0.0197, 95% CI=(0.7465, 0.8233)\n",
      "f1_weighted: 0.8088 | bootstrap mean=0.8082, std=0.0176, 95% CI=(0.7719, 0.8406)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"XGB + GLOVE undersampled\"\n",
    "pipeline_glove_xgb = Pipeline([\n",
    "       #('clf', XGBClassifier(scale_pos_weight=scale_pos_weight_value, random_state=SEED)) \n",
    "       ('clf', XGBClassifier( random_state=SEED)) \n",
    "\n",
    "])\n",
    "pipeline = pipeline_glove_xgb \n",
    "param_grid = param_grid_xgb\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test\n",
    "\n",
    "\n",
    "\n",
    "train_time, best_model, grid_search = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict , y_pred_xgb_gl= evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF + GLOVE undersampled: Training the model...\n",
      "Initial Training Time: 330.0965 ms\n",
      "\n",
      "RF + GLOVE undersampled: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters: {'clf__max_depth': 5, 'clf__max_features': None, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}\n",
      "Best CV Score: 0.7434755551705218\n",
      "\n",
      "--- Evaluating Model: RF + GLOVE undersampled ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7204, std=0.0579, 95% CI=(0.6826, 0.7583)\n",
      "All CV scores for accuracy: [0.66       0.82       0.78       0.72       0.71428571 0.67346939\n",
      " 0.79591837 0.63265306 0.69387755 0.71428571]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7251, std=0.0586, 95% CI=(0.6868, 0.7633)\n",
      "All CV scores for precision_weighted: [0.66025641 0.82051282 0.79166667 0.72141707 0.71921182 0.67712878\n",
      " 0.79756751 0.63265306 0.70355384 0.7265745 ]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7204, std=0.0579, 95% CI=(0.6826, 0.7583)\n",
      "All CV scores for recall_weighted: [0.66       0.82       0.78       0.72       0.71428571 0.67346939\n",
      " 0.79591837 0.63265306 0.69387755 0.71428571]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     16\u001b[39m param_grid = param_grid_rf\n\u001b[32m     18\u001b[39m train_time, best_model, grid_search = train_model_with_gridsearch(\n\u001b[32m     19\u001b[39m     model_name=model_name,\n\u001b[32m     20\u001b[39m     pipeline=pipeline,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m test_result, nfold_results, time_to_predict, y_pred_rf_gl = \u001b[43mevaluate_pipeline_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnfold_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnfold_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_to_predict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_to_predict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_time\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mevaluate_pipeline_model\u001b[39m\u001b[34m(pipeline, model_name, X_train, y_train, X_test, y_test, kf, test_result, nfold_results, time_to_predict, train_time)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Compute CV results\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, scoring \u001b[38;5;129;01min\u001b[39;00m metrics.items():\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     cv_scores[key] = scores\n\u001b[32m     91\u001b[39m     mean = scores.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaque\\anaconda3\\envs\\new_env_modern_slavery\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"RF + GLOVE undersampled\"\n",
    "\n",
    "\n",
    "\n",
    "pipeline_glove_rf = Pipeline([\n",
    "    ('clf', RandomForestClassifier(  random_state=SEED)) \n",
    "])\n",
    "\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test_original\n",
    "\n",
    "\n",
    "pipeline = pipeline_glove_rf\n",
    "param_grid = param_grid_rf\n",
    "\n",
    "train_time, best_model, grid_search = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_rf_gl = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test, and test_result are already defined\n",
    "model_name = \"MLP + GLOVE\"\n",
    "\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test_original\n",
    "\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_grid_mlp = {\n",
    "    'units_dense1': [128, 256],\n",
    "    'activation1': ['relu', 'tanh'],\n",
    "    'dropout_rate': [0.2, 0.3],\n",
    "    'units_dense2': [64, 128],\n",
    "    'activation2': ['relu'],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "}\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    patience=100,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Instantiate the GridSearch tuner and pass the hyperparameters directly\n",
    "tuner = GridSearch(\n",
    "    build_mlp,\n",
    "     objective=Objective('f1', direction='max'),\n",
    "    hyperparameters=param_grid_mlp, # Pass it here\n",
    "    directory='keras_tuner_gridsearch_dir',\n",
    "    project_name='mlp_sbert_gridsearch_tuning',\n",
    "    seed=SEED,\n",
    "    executions_per_trial=10\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=300,\n",
    "             batch_size=64,\n",
    "             validation_split=0.2,\n",
    "             callbacks=[early_stop],    \n",
    "             verbose=1\n",
    ")\n",
    "\n",
    "# Print the search space summary (will reflect the grid)\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Print the results of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\\nBest Hyperparameters: {best_hps.values}\")\n",
    "\n",
    "# Build the best model\n",
    "start_time = time.time()\n",
    "print(f\"Initial Test Time: {start_time:.4f} ms\")\n",
    "best_model =  build_mlp(best_hps)\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop], # Include the early_stop callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "\n",
    "y_pred_mlp_glove = (y_pred_probs > 0.5).astype(int).ravel()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred_mlp_glove, labels, title='Confusion Matrix', cmap='Blues'):\n",
    "    \"\"\"Plots the confusion matrix with percentages.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred_mlp_glove)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=labels)\n",
    "    disp.plot(cmap=cmap, values_format='.2f')\n",
    "    plt.title(f'{title} with Percentages')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_mlp_glove,\n",
    "                        labels=['Negative', 'Positive'],\n",
    "                        title=f'{model_name}: Best Tuned Model (Keras Tuner GridSearch) Confusion Matrix with Percentages',\n",
    "                        cmap='Blues')\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_mlp_glove)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_mlp_glove, average='weighted', zero_division=0)\n",
    "\n",
    "results = {\n",
    "    'Model': model_name,\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    \"Train time\": train_time,\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "}\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([results])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the best model\n",
    "start_time = time.time()\n",
    "print(f\"Initial Test Time: {start_time:.4f} ms\")\n",
    "best_model =  build_mlp(best_hps)\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop], # Include the early_stop callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "\n",
    "y_pred_mlp_glove = (y_pred_probs > 0.5).astype(int).ravel()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred_mlp_glove, labels, title='Confusion Matrix', cmap='Blues'):\n",
    "    \"\"\"Plots the confusion matrix with percentages.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred_mlp_glove)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=labels)\n",
    "    disp.plot(cmap=cmap, values_format='.2f')\n",
    "    plt.title(f'{title} with Percentages')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_mlp_glove,\n",
    "                        labels=['Negative', 'Positive'],\n",
    "                        title=f'{model_name}: Best Tuned Model (Keras Tuner GridSearch) Confusion Matrix with Percentages',\n",
    "                        cmap='Blues')\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_mlp_glove)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_mlp_glove, average='weighted', zero_division=0)\n",
    "\n",
    "results = {\n",
    "    'Model': model_name,\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    \"Train time\": train_time,\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "}\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([results])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost + GLOVE undersampled: Training the model...\n",
      "Initial Training Time: 622.2875 ms\n",
      "\n",
      "AdaBoost + GLOVE undersampled: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters: {'clf__estimator': DecisionTreeClassifier(max_depth=1), 'clf__learning_rate': 0.5, 'clf__n_estimators': 100}\n",
      "Best CV Score: 0.7449053677090831\n",
      "\n",
      "--- Evaluating Model: AdaBoost + GLOVE undersampled ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7126, std=0.0492, 95% CI=(0.6805, 0.7447)\n",
      "All CV scores for accuracy: [0.66       0.76       0.7        0.7        0.73469388 0.81632653\n",
      " 0.71428571 0.65306122 0.65306122 0.73469388]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7170, std=0.0485, 95% CI=(0.6853, 0.7487)\n",
      "All CV scores for precision_weighted: [0.66025641 0.76       0.70292208 0.70292208 0.73486451 0.82069971\n",
      " 0.72932331 0.6530271  0.66867822 0.73760933]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7126, std=0.0492, 95% CI=(0.6805, 0.7447)\n",
      "All CV scores for recall_weighted: [0.66       0.76       0.7        0.7        0.73469388 0.81632653\n",
      " 0.71428571 0.65306122 0.65306122 0.73469388]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7111, std=0.0498, 95% CI=(0.6786, 0.7436)\n",
      "All CV scores for f1_weighted: [0.65986395 0.76       0.6989161  0.6989161  0.73447251 0.81540239\n",
      " 0.71067821 0.65277175 0.64689994 0.733359  ]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 73.7045 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86       366\n",
      "           1       0.39      0.77      0.52        64\n",
      "\n",
      "    accuracy                           0.79       430\n",
      "   macro avg       0.67      0.78      0.69       430\n",
      "weighted avg       0.87      0.79      0.81       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.7884 | bootstrap mean=0.7887, std=0.0196, 95% CI=(0.7488, 0.8256)\n",
      "precision_weighted: 0.8676 | bootstrap mean=0.8684, std=0.0161, 95% CI=(0.8355, 0.8990)\n",
      "recall_weighted: 0.7884 | bootstrap mean=0.7881, std=0.0195, 95% CI=(0.7511, 0.8256)\n",
      "f1_weighted: 0.8129 | bootstrap mean=0.8133, std=0.0171, 95% CI=(0.7778, 0.8452)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_name = 'AdaBoost + GLOVE undersampled'\n",
    "\n",
    "# Define a pipeline with AdaBoost instead of LGBM\n",
    "pipeline_adaboost = Pipeline([\n",
    "    ('clf',  AdaBoostClassifier(\n",
    "        \n",
    "        random_state=SEED))\n",
    "])\n",
    "\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test_original\n",
    "\n",
    "# Set pipeline and param grid\n",
    "pipeline = pipeline_adaboost\n",
    "param_grid = param_grid_adaboost\n",
    "\n",
    "# Train the model\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_result, nfold_results, time_to_predict , y_pred_adam_gl = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time=train_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'BiLSTM + Attention + GLoVe'\n",
    "# Use the specified variables\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_GL\n",
    "y_test = y_test\n",
    "num_classes = 2\n",
    "is_binary = True\n",
    "\n",
    "\n",
    "# Assuming you have pre-processed your text data into sequences of integers\n",
    "# and have a GloVe embedding matrix (embedding_matrix) and vocabulary size (vocab_size)\n",
    "# For demonstration, let's define placeholders:\n",
    "vocab_size_glove = 10000  # Replace with your actual vocabulary size\n",
    "embedding_dim_glove = 300  # Replace with your GloVe embedding dimension\n",
    "embedding_matrix_glove = np.random.rand(vocab_size_glove, embedding_dim_glove) # Replace with your actual GloVe matrix\n",
    "max_length_glove = X_train.shape[1] # Assuming X_train is padded sequences\n",
    "\n",
    "def build_bilstm_attention_glove(hp, vocab_size, embedding_dim, max_length, num_classes, is_binary, embedding_matrix):\n",
    "    input_layer = Input(shape=(max_length,), name='glove_input')\n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)(input_layer)\n",
    "    x = Bidirectional(LSTM(units=hp.Int('lstm_units', 32, 128, step=32),\n",
    "                           return_sequences=True,\n",
    "                           dropout=hp.Float('lstm_dropout', 0.2, 0.5, step=0.1)))(embedding_layer)\n",
    "\n",
    "    class AttentionLayer(Layer):\n",
    "        def __init__(self, **kwargs):\n",
    "            super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1),\n",
    "                                     initializer='random_normal', trainable=True)\n",
    "            super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            scores = tf.nn.softmax(tf.squeeze(tf.matmul(inputs, self.W), axis=-1), axis=1)\n",
    "            scores_expanded = tf.expand_dims(scores, axis=-1)\n",
    "            context_vector = tf.reduce_sum(inputs * scores_expanded, axis=1)\n",
    "            return context_vector\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return (input_shape[0], input_shape[-1])\n",
    "\n",
    "    attention_output = AttentionLayer()(x)\n",
    "\n",
    "    intermediate_units = hp.Int('dense_units', 64, 256, step=64)\n",
    "    x = Dense(intermediate_units, activation='relu')(attention_output)\n",
    "    x = Dropout(hp.Float('dropout_rate', 0.2, 0.5, step=0.1))(x)\n",
    "\n",
    "    if is_binary:\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "        loss_fn = 'binary_crossentropy'\n",
    "        metrics = ['accuracy', F1Score(name='f1_score')]\n",
    "    else:\n",
    "        output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "        loss_fn = 'categorical_crossentropy'\n",
    "        metrics = ['accuracy', F1Score(name='f1_score')]\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss=loss_fn,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model\n",
    "\n",
    "hp_bilstm_attn_glove = HyperParameters()\n",
    "hp_bilstm_attn_glove.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "hp_bilstm_attn_glove.Float('lstm_dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp_bilstm_attn_glove.Int('dense_units', min_value=64, max_value=256, step=64)\n",
    "hp_bilstm_attn_glove.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp_bilstm_attn_glove.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='accuracy', patience=500, restore_best_weights=True)\n",
    "\n",
    "tuner_bilstm_attn_glove = GridSearch(\n",
    "    lambda hp: build_bilstm_attention_glove(hp, vocab_size_glove, embedding_dim_glove, max_length_glove, num_classes, is_binary, embedding_matrix_glove),\n",
    "    objective=Objective(\"f1_score\", direction=\"max\"),\n",
    "    max_trials=10,  # Adjust as needed\n",
    "    directory='bilstm_attn_glove_tune',\n",
    "    project_name='bilstm_attn_glove',\n",
    "    overwrite=True,\n",
    "    hyperparameters=hp_bilstm_attn_glove,\n",
    "    executions_per_trial=1 # Consider increasing for more robust results\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nPerforming Grid Search for BiLSTM with Attention and GloVe...\")\n",
    "tuner_bilstm_attn_glove.search(X_train, y_train,\n",
    "                             epochs=100,  # Adjust as needed\n",
    "                             validation_split=0.1,\n",
    "                             callbacks=[early_stop],\n",
    "                             verbose=1)\n",
    "print(\"Grid Search Finished.\")\n",
    "\n",
    "best_hps_bilstm_attn_glove = tuner_bilstm_attn_glove.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters for BiLSTM with Attention and GloVe:\")\n",
    "print(best_hps_bilstm_attn_glove.values)\n",
    "\n",
    "best_model_bilstm_attn_glove = tuner_bilstm_attn_glove.get_best_models(num_models=1)[0]\n",
    "best_model_bilstm_attn_glove.summary()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "best_model_bilstm_attn_glove.fit(\n",
    "    X_train,\n",
    "    y_train, # Correct y argument\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nEvaluating the Best BiLSTM with Attention and GloVe Model on the Test Set...\")\n",
    "loss_bilstm_attn_glove, acc_bilstm_attn_glove, f1_bilstm_attn_glove = best_model_bilstm_attn_glove.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss_bilstm_attn_glove:.4f}\")\n",
    "print(f\"Accuracy: {acc_bilstm_attn_glove:.4f}\")\n",
    "print(f\"F1 Score: {f1_bilstm_attn_glove:.4f}\")\n",
    "\n",
    "# Predict\n",
    "start_time = time.time()\n",
    "y_pred_probs_glove = best_model_bilstm_attn_glove.predict(X_test)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "\n",
    "y_pred_glove = (y_pred_probs_glove > 0.5).astype(int).flatten() if is_binary else np.argmax(y_pred_probs_glove, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "prec_glove, rec_glove, f1_report_glove, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_glove, average='weighted', zero_division=0)\n",
    "\n",
    "# Save results\n",
    "\n",
    "results = {\n",
    "    'Model': model_name,\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    \"Train time\": train_time,\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "}\n",
    "\n",
    "if 'test_result' not in locals():\n",
    "    test_result = pd.DataFrame()\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([results])], ignore_index=True)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner import HyperParameters, Objective, GridSearch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "is_binary_bert = True\n",
    "is_binary = True\n",
    "\n",
    "\n",
    "model_name = 'LSTM + GloVe'\n",
    "\n",
    "def load_glove_embeddings(filepath):\n",
    "    embeddings_index = {}\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\") # Call the function to load the embeddings\n",
    "embedding_dim = 300\n",
    "SEED = 42\n",
    "# Assuming you have pre-processed your text data into sequences of integers\n",
    "# and have a GloVe embedding matrix (embedding_matrix) and vocabulary size (vocab_size)\n",
    "# For demonstration, let's define placeholders:\n",
    "vocab_size = 10000  # Replace with your actual vocabulary size\n",
    "embedding_dim = 300  # Replace with your GloVe embedding dimension\n",
    "embedding_matrix = np.random.rand(vocab_size, embedding_dim) # Replace with your actual GloVe matrix\n",
    "max_length = X_train.shape[1] # Assuming X_train is padded sequences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare text data for embedding layer\n",
    "tokenizer = Tokenizer(num_words=None, oov_token=\"<unk>\") # Initialize tokenizer\n",
    "tokenizer.fit_on_texts(df['content_corrected'])\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "max_length = 100 # Choose an appropriate max sequence length\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['content_corrected'])\n",
    "X_padded = pad_sequences(X, maxlen=max_length, padding='post', truncating='post')\n",
    "y = df['target'].values\n",
    "\n",
    "\n",
    "\n",
    "# Create embedding matrix from GloVe\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Use the specified variables\n",
    "X_train = X_resampled_GL\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_Gl\n",
    "y_test = y_test_Gl\n",
    "num_classes = 2\n",
    "is_binary = True\n",
    "\n",
    "\n",
    "def build_lstm_glove(hp, vocab_size, embedding_dim, max_length, num_classes, is_binary, embedding_matrix):\n",
    "    input_layer = Input(shape=(max_length,))\n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False)(input_layer)\n",
    "    lstm_units = hp.Int('lstm_units', 32, 128, step=32)\n",
    "    x = LSTM(lstm_units, dropout=hp.Float('dropout_rate', 0.2, 0.5, step=0.1))(embedding_layer)\n",
    "\n",
    "    if is_binary:\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "        loss_fn = 'binary_crossentropy'\n",
    "        metrics = ['accuracy', F1Score(name='f1_score')]\n",
    "    else:\n",
    "        output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "        loss_fn = 'categorical_crossentropy'\n",
    "        metrics = ['accuracy', F1Score(name='f1_score')]\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss=loss_fn,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model\n",
    "\n",
    "hp_glove_lstm = HyperParameters()\n",
    "hp_glove_lstm.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "hp_glove_lstm.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp_glove_lstm.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='accuracy', patience=500, restore_best_weights=True)\n",
    "\n",
    "tuner_glove_lstm = GridSearch(\n",
    "    lambda hp: build_lstm_glove(hp, vocab_size, embedding_dim, max_length, num_classes, is_binary, embedding_matrix),\n",
    "    objective=Objective(\"f1_score\", direction=\"max\"),\n",
    "    max_trials=20,\n",
    "    directory='lstm_glove_gridsearch',\n",
    "    project_name='text_classification_lstm_glove',\n",
    "    overwrite=True,\n",
    "    hyperparameters=hp_glove_lstm\n",
    ")\n",
    "\n",
    "print(\"\\nPerforming Grid Search with GloVe embeddings and LSTM...\")\n",
    "tuner_glove_lstm.search(X_train, y_train,\n",
    "                      epochs=100,\n",
    "                      validation_split=0.1,\n",
    "                      callbacks=[early_stop],\n",
    "                      verbose=1)\n",
    "print(\"Grid Search with GloVe embeddings and LSTM Finished.\")\n",
    "\n",
    "best_hps_glove_lstm = tuner_glove_lstm.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters for GloVe + LSTM:\")\n",
    "print(best_hps_glove_lstm.values)\n",
    "\n",
    "best_model_glove_lstm = tuner_glove_lstm.get_best_models(num_models=1)[0]\n",
    "best_model_glove_lstm.summary()\n",
    "\n",
    "print(\"\\nEvaluating the Best GloVe + LSTM Model on the Test Set...\")\n",
    "loss_glove, acc_glove, f1_glove = best_model_glove_lstm.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss: {loss_glove:.4f}\")\n",
    "print(f\"Accuracy: {acc_glove:.4f}\")\n",
    "print(f\"F1 Score: {f1_glove:.4f}\")\n",
    "\n",
    "start_time = time.time() \n",
    "best_model_glove_lstm.fit(\n",
    "    X_train,\n",
    "    y_train, # Correct y argument\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "\n",
    "# Predict\n",
    "\n",
    "start_time = time.time() \n",
    "y_pred_probs_glove = best_model_glove_lstm.predict(X_test)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "\n",
    "y_pred_glove = (y_pred_probs_glove > 0.5).astype(int).flatten() if is_binary else np.argmax(y_pred_probs_glove, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "prec_glove, rec_glove, f1_report_glove, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_glove, average='weighted', zero_division=0)\n",
    "\n",
    "# Save results\n",
    "\n",
    "results = {\n",
    "    'Model': model_name,\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    \"Train time\": train_time,\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "}\n",
    "\n",
    "if 'test_result' not in locals():\n",
    "    test_result = pd.DataFrame()\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([results])], ignore_index=True)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Recall\n",
    "plot_comparison_bars(\n",
    "\n",
    "\n",
    "    df = test_result[\n",
    "    test_result['Model'].str.contains(\"GLOVE\")\n",
    "].sort_values(\n",
    "    by=['Recall', 'Accuracy'],\n",
    "    ascending=False\n",
    ").drop_duplicates(subset=['Model']),\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, max_features=100000, ngram_range=(1, 3))\n",
    "X_resampled_tf = vectorizer.fit_transform(X_train_resampled)\n",
    "X_test_tf = vectorizer.fit_transform(X_test_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM + TFIDF: Training the model...\n",
      "Initial Training Time: 249.9573 ms\n",
      "\n",
      "SVM + TFIDF: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "Best Parameters: {'clf__C': 1, 'clf__class_weight': None, 'clf__degree': 2, 'clf__gamma': 'scale', 'clf__kernel': 'linear', 'clf__max_iter': 100}\n",
      "Best CV Score: 0.7476809617184952\n",
      "\n",
      "--- Evaluating Model: SVM + TFIDF ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.6439, std=0.0692, 95% CI=(0.5987, 0.6891)\n",
      "All CV scores for accuracy: [0.62       0.74       0.62       0.52       0.67346939 0.71428571\n",
      " 0.53061224 0.67346939 0.65306122 0.69387755]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.6861, std=0.0776, 95% CI=(0.6354, 0.7368)\n",
      "All CV scores for precision_weighted: [0.66447368 0.76041667 0.6875     0.52598753 0.67930029 0.74159664\n",
      " 0.56974863 0.75478807 0.70954985 0.76750317]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.6439, std=0.0692, 95% CI=(0.5987, 0.6891)\n",
      "All CV scores for recall_weighted: [0.62       0.74       0.62       0.52       0.67346939 0.71428571\n",
      " 0.53061224 0.67346939 0.65306122 0.69387755]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.6186, std=0.0821, 95% CI=(0.5649, 0.6722)\n",
      "All CV scores for f1_weighted: [0.59244959 0.73480212 0.58241758 0.49066214 0.67183127 0.70748299\n",
      " 0.47109081 0.64195678 0.62442501 0.6686103 ]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 11.0865 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.12       366\n",
      "           1       0.16      1.00      0.27        64\n",
      "\n",
      "    accuracy                           0.20       430\n",
      "   macro avg       0.58      0.53      0.20       430\n",
      "weighted avg       0.87      0.20      0.14       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.2023 | bootstrap mean=0.2028, std=0.0192, 95% CI=(0.1651, 0.2395)\n",
      "precision_weighted: 0.8746 | bootstrap mean=0.8743, std=0.0120, 95% CI=(0.8512, 0.8980)\n",
      "recall_weighted: 0.2023 | bootstrap mean=0.2019, std=0.0194, 95% CI=(0.1651, 0.2419)\n",
      "f1_weighted: 0.1411 | bootstrap mean=0.1409, std=0.0202, 95% CI=(0.1023, 0.1821)\n",
      "\n",
      "Final Test Result DataFrame:\n",
      "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
      "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
      "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
      "\n",
      "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
      "0             4.92              4.85           4.92       4.98   \n",
      "1             6.92              7.76           6.92       8.21   \n",
      "\n",
      "   Time to Predict (ms)  \n",
      "0                 73.70  \n",
      "1                 11.09  \n"
     ]
    }
   ],
   "source": [
    "model_name = \"SVM + TFIDF\"\n",
    "pipeline_svm = Pipeline([\n",
    "        ('selector', SelectKBest(score_func=chi2, k=500)), \n",
    "    ('clf', SVC(probability=True, random_state=SEED))\n",
    "])\n",
    "\n",
    "pipeline = pipeline_svm\n",
    "param_grid = param_grid_svm\n",
    "X_train = X_resampled_tf\n",
    "y_train = y_train_resampled\n",
    "\n",
    "X_test = X_test_tf\n",
    "y_test = y_test_original\n",
    "\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_svm_bert = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time,\n",
    "    #X_test_source=source_test # Pass the source information for the test set\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Test Result DataFrame:\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>cv_std_accuracy</th>\n",
       "      <th>cv_std_precision</th>\n",
       "      <th>cv_std_recall</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>Time to Predict (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost + GLOVE undersampled</td>\n",
       "      <td>78.84</td>\n",
       "      <td>86.76</td>\n",
       "      <td>78.84</td>\n",
       "      <td>81.29</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.98</td>\n",
       "      <td>73.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM + TFIDF</td>\n",
       "      <td>20.23</td>\n",
       "      <td>87.46</td>\n",
       "      <td>20.23</td>\n",
       "      <td>14.11</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6.92</td>\n",
       "      <td>8.21</td>\n",
       "      <td>11.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
       "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
       "\n",
       "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
       "0             4.92              4.85           4.92       4.98   \n",
       "1             6.92              7.76           6.92       8.21   \n",
       "\n",
       "   Time to Predict (ms)  \n",
       "0                 73.70  \n",
       "1                 11.09  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import GridSearch  # Assuming you are using kerastuner for GridSearch\n",
    "# Assuming X_train, y_train, X_test, y_test, and test_result are already defined\n",
    "model_name = \"MLP + TFIDF\"\n",
    "X_train = X_resampled_tf\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_tf\n",
    "y_test = y_test_original\n",
    "\n",
    "# Define the hyperparameter space\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    mode='max',\n",
    "    patience=100,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Instantiate the GridSearch tuner and pass the hyperparameters directly\n",
    "tuner = GridSearch(\n",
    "    build_mlp,\n",
    "     objective=Objective('f1', direction='max'),\n",
    "    hyperparameters=param_grid_mlp, # Pass it here\n",
    "    directory='keras_tuner_gridsearch_dir',\n",
    "    project_name='mlp_sbert_gridsearch_tuning',\n",
    "    seed=SEED,\n",
    "    executions_per_trial=10\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=300,\n",
    "             batch_size=64,\n",
    "             validation_split=0.2,\n",
    "             callbacks=[early_stop],    \n",
    "             verbose=1\n",
    ")\n",
    "\n",
    "# Print the search space summary (will reflect the grid)\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Print the results of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\\nBest Hyperparameters: {best_hps.values}\")\n",
    "\n",
    "# Build the best model\n",
    "best_model = build_mlp(best_hps)\n",
    "start_time = time.time()\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "train_time = (time.time() - start_time) * 1000\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "start_time = time.time()\n",
    "y_pred_probs = best_model.predict(X_test)\n",
    "predict_time = (time.time() - start_time) * 1000\n",
    "\n",
    "y_pred_mlp_tfidf = (y_pred_probs > 0.5).astype(int).ravel()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred_mlp_tfidf, labels, title='Confusion Matrix', cmap='Blues'):\n",
    "    \"\"\"Plots the confusion matrix with percentages.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred_mlp_tfidf)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=labels)\n",
    "    disp.plot(cmap=cmap, values_format='.2f')\n",
    "    plt.title(f'{title} with Percentages')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_mlp_tfidf,\n",
    "                        labels=['Negative', 'Positive'],\n",
    "                        title=f'{model_name}: Best Tuned Model (Keras Tuner GridSearch) Confusion Matrix with Percentages',\n",
    "                        cmap='Blues')\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred_mlp_tfidf, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "results = {\n",
    "    'Model': model_name,\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    \"Time to predict\": predict_time,\n",
    "    \"Train time\": train_time,\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "}\n",
    "\n",
    "if 'test_result' not in locals():\n",
    "    test_result = pd.DataFrame()\n",
    "\n",
    "test_result = pd.concat([test_result, pd.DataFrame([results])], ignore_index=True)\n",
    "print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost + TFIDF undersampled: Training the model...\n",
      "Initial Training Time: 196.4641 ms\n",
      "\n",
      "AdaBoost + TFIDF undersampled: Running GridSearchCV...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters: {'clf__estimator': DecisionTreeClassifier(max_depth=1), 'clf__learning_rate': 0.5, 'clf__n_estimators': 200}\n",
      "Best CV Score: 0.7434849869994182\n",
      "\n",
      "--- Evaluating Model: AdaBoost + TFIDF undersampled ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7487, std=0.0517, 95% CI=(0.7149, 0.7825)\n",
      "All CV scores for accuracy: [0.72       0.82       0.82       0.76       0.69387755 0.65306122\n",
      " 0.75510204 0.79591837 0.75510204 0.71428571]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7590, std=0.0424, 95% CI=(0.7313, 0.7866)\n",
      "All CV scores for precision_weighted: [0.72141707 0.82467532 0.82051282 0.76       0.70937125 0.70954985\n",
      " 0.76129486 0.79591837 0.77250269 0.71428571]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7487, std=0.0517, 95% CI=(0.7149, 0.7825)\n",
      "All CV scores for recall_weighted: [0.72       0.82       0.82       0.76       0.69387755 0.65306122\n",
      " 0.75510204 0.79591837 0.75510204 0.71428571]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7445, std=0.0580, 95% CI=(0.7066, 0.7824)\n",
      "All CV scores for f1_weighted: [0.71955128 0.81934966 0.81992797 0.76       0.68654214 0.62442501\n",
      " 0.75304061 0.79591837 0.75200989 0.71428571]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 73.1685 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       366\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.85       430\n",
      "   macro avg       0.43      0.50      0.46       430\n",
      "weighted avg       0.72      0.85      0.78       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.8488 | bootstrap mean=0.8486, std=0.0168, 95% CI=(0.8140, 0.8814)\n",
      "precision_weighted: 0.7242 | bootstrap mean=0.7239, std=0.0294, 95% CI=(0.6663, 0.7769)\n",
      "recall_weighted: 0.8488 | bootstrap mean=0.8490, std=0.0171, 95% CI=(0.8140, 0.8814)\n",
      "f1_weighted: 0.7816 | bootstrap mean=0.7816, std=0.0240, 95% CI=(0.7326, 0.8280)\n",
      "\n",
      "Final Test Result DataFrame:\n",
      "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
      "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
      "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
      "2  AdaBoost + TFIDF undersampled     84.88      72.42   84.88     78.16   \n",
      "\n",
      "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
      "0             4.92              4.85           4.92       4.98   \n",
      "1             6.92              7.76           6.92       8.21   \n",
      "2             5.17              4.24           5.17       5.80   \n",
      "\n",
      "   Time to Predict (ms)  \n",
      "0                 73.70  \n",
      "1                 11.09  \n",
      "2                 73.17  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "model_name = 'AdaBoost + TFIDF undersampled'\n",
    "\n",
    "# Define a pipeline with AdaBoost instead of LGBM\n",
    "pipeline_adaboost = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=chi2, k=500)), \n",
    "    ('clf',  AdaBoostClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "\n",
    "# Set pipeline and param grid\n",
    "pipeline = pipeline_adaboost\n",
    "param_grid = param_grid_adaboost\n",
    "\n",
    "\n",
    "# Train the model\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    ")\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_svm_bert = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time,\n",
    "    #X_test_source=source_test # Pass the source information for the test set\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Test Result DataFrame:\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGB + TFIDF undersampled : Training the model...\n",
      "Initial Training Time: 586.2672 ms\n",
      "\n",
      "XGB + TFIDF undersampled : Running GridSearchCV...\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Parameters: {'clf__learning_rate': 0.01, 'clf__max_depth': 18, 'clf__n_estimators': 100, 'clf__subsample': 0.8}\n",
      "Best CV Score: 0.7496488701190663\n",
      "\n",
      "--- Evaluating Model: XGB + TFIDF undersampled  ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7549, std=0.0473, 95% CI=(0.7240, 0.7858)\n",
      "All CV scores for accuracy: [0.74       0.82       0.78       0.74       0.71428571 0.67346939\n",
      " 0.71428571 0.83673469 0.75510204 0.7755102 ]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7620, std=0.0454, 95% CI=(0.7323, 0.7916)\n",
      "All CV scores for precision_weighted: [0.74038462 0.83333333 0.78044872 0.74038462 0.71921182 0.70553936\n",
      " 0.71619685 0.84546094 0.76287658 0.77578322]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7549, std=0.0473, 95% CI=(0.7240, 0.7858)\n",
      "All CV scores for recall_weighted: [0.74       0.82       0.78       0.74       0.71428571 0.67346939\n",
      " 0.71428571 0.83673469 0.75510204 0.7755102 ]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7526, std=0.0499, 95% CI=(0.7200, 0.7852)\n",
      "All CV scores for f1_weighted: [0.73989596 0.81818182 0.77991196 0.73989596 0.71188071 0.65771572\n",
      " 0.71404762 0.83536041 0.75387346 0.7753229 ]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 29.5620 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       366\n",
      "           1       0.50      0.02      0.03        64\n",
      "\n",
      "    accuracy                           0.85       430\n",
      "   macro avg       0.68      0.51      0.47       430\n",
      "weighted avg       0.80      0.85      0.79       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.8512 | bootstrap mean=0.8508, std=0.0178, 95% CI=(0.8140, 0.8860)\n",
      "precision_weighted: 0.8003 | bootstrap mean=0.7934, std=0.0628, 95% CI=(0.6816, 0.8902)\n",
      "recall_weighted: 0.8512 | bootstrap mean=0.8511, std=0.0171, 95% CI=(0.8163, 0.8837)\n",
      "f1_weighted: 0.7871 | bootstrap mean=0.7873, std=0.0245, 95% CI=(0.7392, 0.8335)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = 'XGB + TFIDF undersampled '\n",
    "\n",
    "# Define the ML pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=chi2, k=500)), \n",
    "    ('clf', XGBClassifier(random_state = 42)) \n",
    "])\n",
    "\n",
    "pipeline = pipeline_xgb\n",
    "param_grid = param_grid_xgb\n",
    "\n",
    "# Train the model\n",
    "\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    ")\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_xgb_tfidf = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR + TFIDF : Training the model...\n",
      "Initial Training Time: 268.6541 ms\n",
      "\n",
      "LR + TFIDF : Running GridSearchCV...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Parameters: {'clf__C': 10, 'clf__max_iter': 100, 'clf__penalty': 'l1', 'clf__solver': 'saga'}\n",
      "Best CV Score: 0.7415689720913966\n",
      "\n",
      "--- Evaluating Model: LR + TFIDF  ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7490, std=0.0598, 95% CI=(0.7099, 0.7881)\n",
      "All CV scores for accuracy: [0.74       0.8        0.72       0.74       0.65306122 0.67346939\n",
      " 0.71428571 0.83673469 0.7755102  0.83673469]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7595, std=0.0564, 95% CI=(0.7227, 0.7964)\n",
      "All CV scores for precision_weighted: [0.74350649 0.80788177 0.72577997 0.74038462 0.65825277 0.72531715\n",
      " 0.71524772 0.83872741 0.80111184 0.83926012]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7490, std=0.0598, 95% CI=(0.7099, 0.7881)\n",
      "All CV scores for recall_weighted: [0.74       0.8        0.72       0.74       0.65306122 0.67346939\n",
      " 0.71428571 0.83673469 0.7755102  0.83673469]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7453, std=0.0635, 95% CI=(0.7039, 0.7868)\n",
      "All CV scores for f1_weighted: [0.73906062 0.79871176 0.71819646 0.73989596 0.64866031 0.65064736\n",
      " 0.71356904 0.83632517 0.77152349 0.83659864]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 8.1100 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       366\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.85       430\n",
      "   macro avg       0.43      0.50      0.46       430\n",
      "weighted avg       0.72      0.85      0.78       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.8512 | bootstrap mean=0.8514, std=0.0173, 95% CI=(0.8186, 0.8860)\n",
      "precision_weighted: 0.7245 | bootstrap mean=0.7251, std=0.0299, 95% CI=(0.6663, 0.7811)\n",
      "recall_weighted: 0.8512 | bootstrap mean=0.8516, std=0.0170, 95% CI=(0.8186, 0.8838)\n",
      "f1_weighted: 0.7827 | bootstrap mean=0.7834, std=0.0246, 95% CI=(0.7337, 0.8292)\n",
      "Model pipeline saved to best_lr_pipeline.pkl\n",
      "\n",
      "Final Test Result DataFrame:\n",
      "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
      "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
      "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
      "2  AdaBoost + TFIDF undersampled     84.88      72.42   84.88     78.16   \n",
      "3      XGB + TFIDF undersampled      85.12      80.03   85.12     78.71   \n",
      "4                    LR + TFIDF      85.12      72.45   85.12     78.27   \n",
      "\n",
      "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
      "0             4.92              4.85           4.92       4.98   \n",
      "1             6.92              7.76           6.92       8.21   \n",
      "2             5.17              4.24           5.17       5.80   \n",
      "3             4.73              4.54           4.73       4.99   \n",
      "4             5.98              5.64           5.98       6.35   \n",
      "\n",
      "   Time to Predict (ms)  \n",
      "0                 73.70  \n",
      "1                 11.09  \n",
      "2                 73.17  \n",
      "3                 29.56  \n",
      "4                  8.11  \n"
     ]
    }
   ],
   "source": [
    "model_name = 'LR + TFIDF '\n",
    "\n",
    "# Define the ML pipeline\n",
    "pipeline_lr = Pipeline([\n",
    "    #('selector', SelectKBest(score_func=chi2, k=500)), \n",
    "    ('clf', LogisticRegression(  random_state = 42)) \n",
    "])\n",
    "pipeline = pipeline_lr\n",
    "param_grid = param_grid_lr\n",
    "\n",
    "X_train = X_resampled_tf\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_tf\n",
    "y_test = y_test_original\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = \"f1\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_lr_tfidf= evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time,\n",
    "    #X_test_source=source_test # Pass the source information for the test set\n",
    "\n",
    "    )\n",
    "joblib.dump(best_model, 'best_lr_pipeline.pkl')\n",
    "print(\"Model pipeline saved to best_lr_pipeline.pkl\")\n",
    "print(\"\\nFinal Test Result DataFrame:\")\n",
    "print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>cv_std_accuracy</th>\n",
       "      <th>cv_std_precision</th>\n",
       "      <th>cv_std_recall</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>Time to Predict (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost + GLOVE undersampled</td>\n",
       "      <td>78.84</td>\n",
       "      <td>86.76</td>\n",
       "      <td>78.84</td>\n",
       "      <td>81.29</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.98</td>\n",
       "      <td>73.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM + TFIDF</td>\n",
       "      <td>20.23</td>\n",
       "      <td>87.46</td>\n",
       "      <td>20.23</td>\n",
       "      <td>14.11</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6.92</td>\n",
       "      <td>8.21</td>\n",
       "      <td>11.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost + TFIDF undersampled</td>\n",
       "      <td>84.88</td>\n",
       "      <td>72.42</td>\n",
       "      <td>84.88</td>\n",
       "      <td>78.16</td>\n",
       "      <td>5.17</td>\n",
       "      <td>4.24</td>\n",
       "      <td>5.17</td>\n",
       "      <td>5.80</td>\n",
       "      <td>73.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB + TFIDF undersampled</td>\n",
       "      <td>85.12</td>\n",
       "      <td>80.03</td>\n",
       "      <td>85.12</td>\n",
       "      <td>78.71</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.99</td>\n",
       "      <td>29.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR + TFIDF</td>\n",
       "      <td>85.12</td>\n",
       "      <td>72.45</td>\n",
       "      <td>85.12</td>\n",
       "      <td>78.27</td>\n",
       "      <td>5.98</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.35</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
       "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
       "2  AdaBoost + TFIDF undersampled     84.88      72.42   84.88     78.16   \n",
       "3      XGB + TFIDF undersampled      85.12      80.03   85.12     78.71   \n",
       "4                    LR + TFIDF      85.12      72.45   85.12     78.27   \n",
       "\n",
       "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
       "0             4.92              4.85           4.92       4.98   \n",
       "1             6.92              7.76           6.92       8.21   \n",
       "2             5.17              4.24           5.17       5.80   \n",
       "3             4.73              4.54           4.73       4.99   \n",
       "4             5.98              5.64           5.98       6.35   \n",
       "\n",
       "   Time to Predict (ms)  \n",
       "0                 73.70  \n",
       "1                 11.09  \n",
       "2                 73.17  \n",
       "3                 29.56  \n",
       "4                  8.11  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF + TFIDF : Training the model...\n",
      "Initial Training Time: 332.4599 ms\n",
      "\n",
      "RF + TFIDF : Running GridSearchCV...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters: {'clf__max_depth': 20, 'clf__max_features': 'sqrt', 'clf__min_samples_split': 15, 'clf__n_estimators': 100}\n",
      "Best CV Score: 0.7701268223340507\n",
      "\n",
      "--- Evaluating Model: RF + TFIDF  ---\n",
      "Performing cross-validation...\n",
      "\n",
      "ACCURACY CV: mean=0.7548, std=0.0521, 95% CI=(0.7208, 0.7889)\n",
      "All CV scores for accuracy: [0.76       0.8        0.8        0.78       0.7755102  0.67346939\n",
      " 0.67346939 0.83673469 0.73469388 0.71428571]\n",
      "\n",
      "PRECISION_WEIGHTED CV: mean=0.7658, std=0.0429, 95% CI=(0.7377, 0.7939)\n",
      "All CV scores for precision_weighted: [0.76       0.80193237 0.80193237 0.78044872 0.77578322 0.75478807\n",
      " 0.67930029 0.83872741 0.74595355 0.71921182]\n",
      "\n",
      "RECALL_WEIGHTED CV: mean=0.7548, std=0.0521, 95% CI=(0.7208, 0.7889)\n",
      "All CV scores for recall_weighted: [0.76       0.8        0.8        0.78       0.7755102  0.67346939\n",
      " 0.67346939 0.83673469 0.73469388 0.71428571]\n",
      "\n",
      "F1_WEIGHTED CV: mean=0.7509, std=0.0579, 95% CI=(0.7131, 0.7888)\n",
      "All CV scores for f1_weighted: [0.76       0.79967949 0.79967949 0.77991196 0.7753229  0.64195678\n",
      " 0.67183127 0.83632517 0.73246909 0.71188071]\n",
      "\n",
      "Predicting on test set...\n",
      "Prediction time: 18.7387 ms\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       366\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.85       430\n",
      "   macro avg       0.43      0.50      0.46       430\n",
      "weighted avg       0.72      0.85      0.78       430\n",
      "\n",
      "\n",
      "Test Metrics with 95% bootstrap CIs:\n",
      "accuracy: 0.8512 | bootstrap mean=0.8511, std=0.0168, 95% CI=(0.8163, 0.8837)\n",
      "precision_weighted: 0.7245 | bootstrap mean=0.7242, std=0.0297, 95% CI=(0.6663, 0.7810)\n",
      "recall_weighted: 0.8512 | bootstrap mean=0.8510, std=0.0169, 95% CI=(0.8163, 0.8815)\n",
      "f1_weighted: 0.7827 | bootstrap mean=0.7836, std=0.0247, 95% CI=(0.7337, 0.8325)\n",
      "\n",
      "Final Test Result DataFrame:\n",
      "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
      "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
      "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
      "2  AdaBoost + TFIDF undersampled     84.88      72.42   84.88     78.16   \n",
      "3      XGB + TFIDF undersampled      85.12      80.03   85.12     78.71   \n",
      "4                    LR + TFIDF      85.12      72.45   85.12     78.27   \n",
      "5                    RF + TFIDF      85.12      72.45   85.12     78.27   \n",
      "\n",
      "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
      "0             4.92              4.85           4.92       4.98   \n",
      "1             6.92              7.76           6.92       8.21   \n",
      "2             5.17              4.24           5.17       5.80   \n",
      "3             4.73              4.54           4.73       4.99   \n",
      "4             5.98              5.64           5.98       6.35   \n",
      "5             5.21              4.29           5.21       5.79   \n",
      "\n",
      "   Time to Predict (ms)  \n",
      "0                 73.70  \n",
      "1                 11.09  \n",
      "2                 73.17  \n",
      "3                 29.56  \n",
      "4                  8.11  \n",
      "5                 18.74  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFinal Test Result DataFrame:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(test_result)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m joblib.dump(best_model, os.path.join(\u001b[43moutput_dir\u001b[49m,\u001b[33m'\u001b[39m\u001b[33mbest_rf_pipeline2.pkl\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel pipeline saved to best_rf_pipeline.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m joblib.dump(X_test_tf, os.path.join(\u001b[33m'\u001b[39m\u001b[33mX_test_tf2.joblib\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_name = 'RF + TFIDF '\n",
    "\n",
    "# Define the ML pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=chi2, k=500)), \n",
    "    ('clf', RandomForestClassifier( random_state=SEED)) \n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "pipeline = pipeline_rf\n",
    "param_grid = param_grid_rf\n",
    "X_train = X_resampled_tf\n",
    "y_train = y_train_resampled\n",
    "X_test = X_test_tf\n",
    "y_test = y_test_original\n",
    "\n",
    "\n",
    "best_model, grid_search, train_time = train_model_with_gridsearch(\n",
    "    model_name=model_name,\n",
    "    pipeline=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    scoring = 'f1'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_result, nfold_results, time_to_predict, y_pred_svm_bert = evaluate_pipeline_model(\n",
    "    pipeline=best_model,\n",
    "    model_name=model_name,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    kf=kf,\n",
    "    test_result=test_result,\n",
    "    nfold_results=nfold_results,\n",
    "    time_to_predict=time_to_predict,\n",
    "    train_time = train_time,\n",
    "    #X_test_source=source_test # Pass the source information for the test set\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Test Result DataFrame:\")\n",
    "print(test_result)\n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(best_model, os.path.join(output_dir,'best_rf_pipeline2.pkl'))\n",
    "print(\"Model pipeline saved to best_rf_pipeline.pkl\")\n",
    "joblib.dump(X_test_tf, os.path.join('X_test_tf2.joblib'))\n",
    "joblib.dump(y_test_tf, os.path.join(output_dir,'y_test_tf2.joblib'))\n",
    "joblib.dump(source_test, os.path.join(output_dir,'source_test2.joblib'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Neural Networks Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Recall\n",
    "plot_comparison_bars(\n",
    "\n",
    "\n",
    "    df = test_result[\n",
    "    test_result['Model'].str.contains(\"TFIDF\")\n",
    "].sort_values(\n",
    "    by=['Accuracy'],\n",
    "    ascending=False\n",
    ").drop_duplicates(subset=['Model']),\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold_results_df = pd.DataFrame(nfold_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>cv_std_accuracy</th>\n",
       "      <th>cv_std_precision</th>\n",
       "      <th>cv_std_recall</th>\n",
       "      <th>cv_std_f1</th>\n",
       "      <th>Time to Predict (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost + GLOVE undersampled</td>\n",
       "      <td>78.84</td>\n",
       "      <td>86.76</td>\n",
       "      <td>78.84</td>\n",
       "      <td>81.29</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.98</td>\n",
       "      <td>73.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM + TFIDF</td>\n",
       "      <td>20.23</td>\n",
       "      <td>87.46</td>\n",
       "      <td>20.23</td>\n",
       "      <td>14.11</td>\n",
       "      <td>6.92</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6.92</td>\n",
       "      <td>8.21</td>\n",
       "      <td>11.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost + TFIDF undersampled</td>\n",
       "      <td>84.88</td>\n",
       "      <td>72.42</td>\n",
       "      <td>84.88</td>\n",
       "      <td>78.16</td>\n",
       "      <td>5.17</td>\n",
       "      <td>4.24</td>\n",
       "      <td>5.17</td>\n",
       "      <td>5.80</td>\n",
       "      <td>73.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB + TFIDF undersampled</td>\n",
       "      <td>85.12</td>\n",
       "      <td>80.03</td>\n",
       "      <td>85.12</td>\n",
       "      <td>78.71</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.99</td>\n",
       "      <td>29.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR + TFIDF</td>\n",
       "      <td>85.12</td>\n",
       "      <td>72.45</td>\n",
       "      <td>85.12</td>\n",
       "      <td>78.27</td>\n",
       "      <td>5.98</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.35</td>\n",
       "      <td>8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF + TFIDF</td>\n",
       "      <td>85.12</td>\n",
       "      <td>72.45</td>\n",
       "      <td>85.12</td>\n",
       "      <td>78.27</td>\n",
       "      <td>5.21</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.79</td>\n",
       "      <td>18.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  Precision  Recall  F1 Score  \\\n",
       "0  AdaBoost + GLOVE undersampled     78.84      86.76   78.84     81.29   \n",
       "1                    SVM + TFIDF     20.23      87.46   20.23     14.11   \n",
       "2  AdaBoost + TFIDF undersampled     84.88      72.42   84.88     78.16   \n",
       "3      XGB + TFIDF undersampled      85.12      80.03   85.12     78.71   \n",
       "4                    LR + TFIDF      85.12      72.45   85.12     78.27   \n",
       "5                    RF + TFIDF      85.12      72.45   85.12     78.27   \n",
       "\n",
       "   cv_std_accuracy  cv_std_precision  cv_std_recall  cv_std_f1  \\\n",
       "0             4.92              4.85           4.92       4.98   \n",
       "1             6.92              7.76           6.92       8.21   \n",
       "2             5.17              4.24           5.17       5.80   \n",
       "3             4.73              4.54           4.73       4.99   \n",
       "4             5.98              5.64           5.98       6.35   \n",
       "5             5.21              4.29           5.21       5.79   \n",
       "\n",
       "   Time to Predict (ms)  \n",
       "0                 73.70  \n",
       "1                 11.09  \n",
       "2                 73.17  \n",
       "3                 29.56  \n",
       "4                  8.11  \n",
       "5                 18.74  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of dictionaries to DataFrame\n",
    "nfold_results_df = pd.DataFrame(nfold_results)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Column names in DataFrame:\", nfold_results_df.columns)\n",
    "\n",
    "# Ensure correct column names\n",
    "if 'model' in nfold_results_df.columns and 'recall' in nfold_results_df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for model in nfold_results_df['model'].unique():\n",
    "        # Extract accuracy scores (each value is a list)\n",
    "        model_scores = nfold_results_df[nfold_results_df['model'] == model]['recall'].explode().astype(float)\n",
    "        \n",
    "        # Plot individual accuracy scores across cross-validation folds\n",
    "        plt.plot(range(1, len(model_scores) + 1), model_scores, marker='.', linestyle='-', label=model)\n",
    "\n",
    "    plt.xlabel('Cross-validation Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Cross-validation Recall per Model')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Columns 'model' or 'accuracy' not found in nfold_results_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = nfold_results_df[[\"model\",\"recall\"]].explode(\"recall\").groupby(\"model\").mean()*100\n",
    "accuracy_df = nfold_results_df[[\"model\",\"accuracy\"]].explode(\"accuracy\").groupby(\"model\").mean()*100\n",
    "\n",
    "recall_df.reset_index(\"model\",inplace= True)\n",
    "accuracy_df.reset_index(\"model\",inplace= True)\n",
    "\n",
    "\n",
    "comparison_df = accuracy_df.merge(recall_df, on=\"model\")\n",
    "comparison_df['model'] = comparison_df['model'].replace(\"RandomForest + TFIDF \", \"RF + TFIDF\")\n",
    "comparison_df['model'] = comparison_df['model'].replace(\"XGBClassifier + TFIDF \", \"XGB + TFIDF\")\n",
    "comparison_df['model'] = comparison_df['model'].replace(\"LIGHTGBM + SBERT\", \"LGBM + SBERT\")\n",
    "comparison_df.set_index(\"model\", inplace=True)\n",
    "\n",
    "# Accuracy vs Recall\n",
    "plot_comparison_bars(\n",
    "    df=test_result.sort_values(by=['Recall']).drop_duplicates(),\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_results = nfold_results_df.groupby(\"model\").agg({\n",
    "        \"recall\": \"mean\",\n",
    "        \"accuracy\": \"mean\"\n",
    "    }).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_name = 'LSTM '\n",
    "\n",
    "# Extract X and y\n",
    "texts = df['content_corrected'].values # Get as numpy array of strings\n",
    "labels = df['target'].values\n",
    "\n",
    "# --- Check and Prepare Labels ---\n",
    "if isinstance(labels[0], str):\n",
    "    print(\"Labels appear to be strings. Encoding labels...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(f\"Found {num_classes} classes: {label_encoder.classes_}\")\n",
    "    is_binary = num_classes == 2\n",
    "else:\n",
    "    print(\"Labels appear to be numerical. Assuming they start from 0.\")\n",
    "    y = labels.astype(int)\n",
    "    num_classes = len(np.unique(y))\n",
    "    is_binary = num_classes == 2\n",
    "    print(f\"Found {num_classes} classes.\")\n",
    "\n",
    "\n",
    "# --- 2. Preprocessing Text ---\n",
    "\n",
    "# Tokenization\n",
    "max_words = 5000  # Max number of words to keep in vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\") # oov_token handles words not in vocab\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1 # +1 because index 0 is reserved\n",
    "print(f\"Found {len(word_index)} unique tokens. Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Padding\n",
    "max_sequence_length = 150 # Adjust based on your text lengths (find the max or use a percentile)\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "print('Shape of data tensor (X):', X.shape)\n",
    "print('Shape of label tensor (y):', y.shape)\n",
    "\n",
    "\n",
    "print('Shape of X_train tensor:', X_train_original.shape)\n",
    "print('Shape of y_train tensor:', y_train.shape)\n",
    "print('Shape of X_test tensor:', X_test_original.shape)\n",
    "print('Shape of y_test tensor:', y_test.shape)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "# --- 4. Build the LSTM Model ---\n",
    "\n",
    "embedding_dim = 128   # Dimension of the word embeddings\n",
    "lstm_units = 64      # Number of units in the LSTM layer\n",
    "dropout_rate = 0.4    # Dropout rate for regularization\n",
    "\n",
    "# --- 4. Define the Model Building Function for Keras Tuner ---\n",
    "def build_lstm(hp: HyperParameters):\n",
    "    embedding_dim = hp.Int('embedding_dim', min_value=64, max_value=256, step=32)\n",
    "    lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    spatial_dropout = hp.Boolean('spatial_dropout', default=False)\n",
    "\n",
    "    model = Sequential(name=\"LSTM_Tuned\")\n",
    "    model.add(Embedding(input_dim=vocab_size,\n",
    "                      output_dim=embedding_dim,\n",
    "                      input_length=max_sequence_length,\n",
    "                      mask_zero=True))\n",
    "    if spatial_dropout:\n",
    "        model.add(SpatialDropout1D(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_units,\n",
    "                      dropout=dropout_rate,\n",
    "                      recurrent_dropout=dropout_rate))\n",
    "    if is_binary:\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "    if is_binary:\n",
    "        loss_function = 'binary_crossentropy'\n",
    "    else:\n",
    "        loss_function = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_function,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- 5. Define the Hyperparameter Space for Grid Search ---FBV\n",
    "hp = HyperParameters()\n",
    "hp.Int('embedding_dim', min_value=64, max_value=256, step=32)\n",
    "hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp.Boolean('spatial_dropout', default=False)\n",
    "\n",
    "# --- 6. Instantiate the Grid Search Tuner ---\n",
    "tuner = GridSearch(\n",
    "    build_lstm,\n",
    "    objective='accuracy',  # Metric to optimize\n",
    "    max_trials=20,             # Number of different hyperparameter combinations to try\n",
    "    directory='lstm_gridsearch', # Directory to save results\n",
    "    project_name='text_classification_lstm',\n",
    "    overwrite=True,            # Overwrite existing runs if the project name is the same\n",
    "    hyperparameters=hp        # Explicitly pass the hyperparameter space\n",
    ")\n",
    "\n",
    "# --- 7. Perform the Grid Search ---\n",
    "print(\"\\nPerforming Grid Search...\")\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=100,             # Number of epochs to train each model configuration\n",
    "             )\n",
    "\n",
    "print(\"Grid Search Finished.\")\n",
    "\n",
    "# --- 8. Get the Best Hyperparameters and Model ---\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"Embedding Dimension: {best_hps.get('embedding_dim')}\")\n",
    "print(f\"LSTM Units: {best_hps.get('lstm_units')}\")\n",
    "print(f\"Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Spatial Dropout: {best_hps.get('spatial_dropout')}\")\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n",
    "\n",
    "# --- 9. Evaluate the Best Model on the Test Set ---\n",
    "print(\"\\nEvaluating the Best Model on the Test Set...\")\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss of the Best Model: {loss:.4f}')\n",
    "print(f'Test Accuracy of the Best Model: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    y_test, y_pred,\n",
    "    labels=['Negative', 'Positive'],\n",
    "    title=f'{model_name}: Confusion Matrix with Percentages',\n",
    "    cmap='Blues'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = sum(word_counts.values())\n",
    "cumulative_frequency = 0\n",
    "selected_words = 0\n",
    "threshold_percentage = 0.95\n",
    "\n",
    "for i, (word, count) in enumerate(most_common):\n",
    "    cumulative_frequency += count\n",
    "    if cumulative_frequency / total_words >= threshold_percentage:\n",
    "        selected_words = i + 1\n",
    "        break\n",
    "\n",
    "print(f\"Number of words covering {threshold_percentage*100:.2f}% of the vocabulary: {selected_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'BiLSTM'\n",
    "\n",
    "# --- 1. Extract X and y ---\n",
    "texts = df['content_corrected'].astype(str).values\n",
    "labels = df['target'].values\n",
    "\n",
    "# --- Check and Prepare Labels ---\n",
    "if isinstance(labels[0], str):\n",
    "    print(\"Labels appear to be strings. Encoding labels...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(labels)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(f\"Found {num_classes} classes: {label_encoder.classes_}\")\n",
    "    is_binary = num_classes == 2\n",
    "else:\n",
    "    print(\"Labels appear to be numerical. Assuming they start from 0.\")\n",
    "    y = labels.astype(int)\n",
    "    num_classes = len(np.unique(y))\n",
    "    is_binary = num_classes == 2\n",
    "    print(f\"Found {num_classes} classes.\")\n",
    "\n",
    "# --- 2. Preprocessing Text ---\n",
    "max_words = 5000 \n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "actual_vocab_size = max_words\n",
    "print(f\"Found {len(word_index)} unique tokens. Using vocab size: {actual_vocab_size}\")\n",
    "\n",
    "max_sequence_length = 150\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "print('Shape of data tensor (X):', X.shape)\n",
    "print('Shape of label tensor (y):', y.shape)\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train, y_train= rus.fit_resample(X_train_original, y_train)\n",
    "print('Shape of X_train tensor:', X_train_original.shape)\n",
    "print('Shape of y_train tensor:', y_train.shape)\n",
    "print('Shape of X_test tensor:', X_test_original.shape)\n",
    "print('Shape of y_test tensor:', y_test.shape)\n",
    "\n",
    "def build_model(hp):\n",
    "    embedding_dim = hp.Int('embedding_dim', min_value=64, max_value=256, step=32)\n",
    "    lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    spatial_dropout_rate = hp.Float('spatial_dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "    intermediate_units = hp.Int('intermediate_units', min_value=32, max_value=128, step=32)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "\n",
    "    # Input Layer\n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32', name='input_sequence')\n",
    "\n",
    "    # Embedding Layer\n",
    "    embedded_sequences = Embedding(input_dim=actual_vocab_size,\n",
    "                                   output_dim=embedding_dim,\n",
    "                                   input_length=max_sequence_length,\n",
    "                                   mask_zero=True,\n",
    "                                   name='embedding')(sequence_input)\n",
    "\n",
    "    # Spatial Dropout\n",
    "    spatial_dropout = SpatialDropout1D(spatial_dropout_rate, name='spatial_dropout')(embedded_sequences)\n",
    "\n",
    "    # BiLSTM\n",
    "    bilstm_out = Bidirectional(LSTM(units=lstm_units, dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True),\n",
    "                               name='bidirectional_lstm')(spatial_dropout)\n",
    "\n",
    "    # Attention Layer\n",
    "    class AttentionLayer(Layer):\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(name='attention_weight',\n",
    "                                     shape=(input_shape[-1], 1),\n",
    "                                     initializer='uniform',\n",
    "                                     trainable=True)\n",
    "        def call(self, inputs):\n",
    "            scores = tf.matmul(inputs, self.W)\n",
    "            scores = tf.squeeze(scores, axis=-1)\n",
    "            weights = tf.nn.softmax(scores, axis=1)\n",
    "            weighted_output = inputs * tf.expand_dims(weights, axis=-1)\n",
    "            context_vector = tf.reduce_sum(weighted_output, axis=1)\n",
    "            return context_vector, weights\n",
    "\n",
    "    attention_out, _ = AttentionLayer(name='attention_layer')(bilstm_out)\n",
    "\n",
    "    dense = Dense(units=intermediate_units, activation='relu', name='intermediate_dense')(attention_out)\n",
    "    dropout_final = Dropout(dropout_rate, name='final_dropout')(dense)\n",
    "\n",
    "    # Output\n",
    "    if is_binary:\n",
    "        output_layer = Dense(1, activation='sigmoid', name='output_layer')(dropout_final)\n",
    "    else:\n",
    "        output_layer = Dense(num_classes, activation='softmax', name='output_layer')(dropout_final)\n",
    "\n",
    "    # ‚úÖ Model defined BEFORE compile\n",
    "    model = Model(inputs=sequence_input, outputs=[output_layer, _], name='BiLSTM_Attention_Classifier')\n",
    "\n",
    "    # Compile\n",
    "    if is_binary:\n",
    "        loss_function = 'binary_crossentropy'\n",
    "        metrics_list = [F1Score(name='f1_score'), None]\n",
    "    else:\n",
    "        loss_function = 'sparse_categorical_crossentropy'\n",
    "        metrics_list = [F1Score(name='f1_score'), None]\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=[loss_function, None],\n",
    "        metrics=metrics_list\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Update your hp definition\n",
    "hp = HyperParameters()\n",
    "hp.Int('embedding_dim', min_value=64, max_value=256, step=32)\n",
    "hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
    "hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp.Float('spatial_dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "hp.Int('intermediate_units', min_value=32, max_value=128, step=32)\n",
    "hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "hp.Choice('max_sequence_length', values=[50, 100, 150, 200])\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_output_layer_accuracy',\n",
    "    mode='max',\n",
    "    patience=500,\n",
    "    restore_best_weights=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# --- Update the GridSearch tuner to optimize for F1 Score ---\n",
    "tuner = GridSearch(\n",
    "    build_model,\n",
    "    objective=Objective('output_layer_f1_score', direction='max'),  # <<< changed here\n",
    "    max_trials=100,\n",
    "    executions_per_trial=3,\n",
    "    directory='gridsearch_dir',\n",
    "    project_name='bilstm_attention_gridsearch',\n",
    "    hyperparameters=hp\n",
    ")\n",
    "\n",
    "\n",
    "# --- 7. Perform the Grid Search ---\n",
    "print(\"\\nStarting Grid Search...\")\n",
    "tuner.search(X_train,  [y_test, np.zeros((y_test.shape[0], X_test.shape[1]))],\n",
    "             epochs=300, # Reduced epochs for demonstration\n",
    "             validation_split=0.1,\n",
    "             #callbacks=[EarlyStopping(monitor='val_output_layer_accuracy', patience=2, restore_best_weights=True)],\n",
    "             verbose=1)\n",
    "print(\"Grid Search Finished.\")\n",
    "\n",
    "# --- 8. Get the Best Hyperparameters and Model ---\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n",
    "\n",
    "\n",
    "best_model.fit(\n",
    "    X_train,\n",
    "     [y_train, np.zeros((y_train.shape[0], X_train.shape[1]))],\n",
    "    epochs=2000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1)\n",
    "\n",
    "y_pred_probs, attention_weights = best_model.predict(X_test)\n",
    "\n",
    "if is_binary:\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "else:\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "best_results = {\n",
    "    'Model': 'BiLSTM',\n",
    "    \"Accuracy\": round(acc * 100, 4),\n",
    "    \"Precision\": round(prec * 100, 4),\n",
    "    \"Recall\": round(rec * 100, 4),\n",
    "    \"F1 Score\": round(f1 * 100, 4),\n",
    "    'Best Hyperparameters': best_hps.values\n",
    "}\n",
    "\n",
    "print(best_results)\n",
    "\n",
    "# Assuming 'test_result' DataFrame exists from your original code\n",
    "# For demonstration, let's initialize it if it doesn't\n",
    "if 'test_result' not in locals():\n",
    "    test_result = pd.DataFrame()\n",
    "\n",
    "# Create a DataFrame from the best results dictionary\n",
    "new_row_df = pd.DataFrame([best_results])\n",
    "\n",
    "# Concatenate the existing test_result DataFrame with the new row DataFrame\n",
    "test_result = pd.concat([test_result, new_row_df], ignore_index=True)\n",
    "\n",
    "print(\"\\nUpdated Test Results DataFrame:\")\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_comparison_bars(\n",
    "    df,\n",
    "    model_col='Model',\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)',\n",
    "    sort_by='Accuracy',\n",
    "    baseline_acc = 75\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced side-by-side bar chart comparing two metrics across models,\n",
    "    with automatic mean baselines for both.\n",
    "    \"\"\"\n",
    "    # --- Sort Data ---\n",
    "    df = df.sort_values(by=sort_by, ascending=False).reset_index(drop=True)\n",
    "\n",
    "    labels = df[model_col].tolist()\n",
    "    metric1 = df[metric1_col].tolist()\n",
    "    metric2 = df[metric2_col].tolist()\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.7   # Wider bars\n",
    "    gap = 0.60     # More spacing\n",
    "    x_spaced = x * (1 + gap)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22, 10))\n",
    "\n",
    "    # Bar colors\n",
    "    colors = ['#4E79A7', '#F28E2B']\n",
    "\n",
    "    # Plot bars\n",
    "    rects1 = ax.bar(x_spaced - width/2, metric1, width, label=name_metric1, color=colors[0])\n",
    "    rects2 = ax.bar(x_spaced + width/2, metric2, width, label=name_metric2, color=colors[1])\n",
    "\n",
    "    # Add labels on top of bars\n",
    "    def add_labels(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate(f'{height:.2f}',\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 8),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=10,\n",
    "                        path_effects=[pe.withStroke(linewidth=2, foreground=\"white\")])\n",
    "\n",
    "    add_labels(rects1)\n",
    "    add_labels(rects2)\n",
    "\n",
    "    # Axis styling\n",
    "    ax.set_ylabel('Score (%)', fontsize=13)\n",
    "    ax.set_title(f'Model Comparison: {name_metric1} vs {name_metric2}', fontsize=16)\n",
    "    ax.set_xticks(x_spaced)\n",
    "    ax.set_xticklabels(labels, rotation=30, ha='right', fontsize=11)\n",
    "    ax.set_ylim(0, max(max(metric1), max(metric2)) + 10)\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Baselines: Mean Accuracy and Mean Recall ---\n",
    "\n",
    "    ax.axhline(\n",
    "        y=baseline_acc,\n",
    "        color=colors[0],\n",
    "        linestyle='--',\n",
    "        linewidth=1.5,\n",
    "        label=f'Mean {name_metric1}: ({baseline_acc:.2f}%)'\n",
    "    )\n",
    "\n",
    "    # Legend\n",
    "    ax.legend(title='Metrics & Baselines', loc='lower left', fontsize=11, title_fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = pd.read_csv('model_comparison_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result  = test_result[test_result['Model'] != 'BiLSTM with GloVe'].reset_index(drop=True)\n",
    "test_result['Model'] = test_result['Model'].str.replace('undersampled', '').str.strip()\n",
    "\n",
    "# Accuracy vs Recall\n",
    "plot_comparison_bars(\n",
    "    df=test_result.sort_values(by=['Recall'],ascending=False).drop_duplicates(subset=['Model']),\n",
    "    metric1_col='Accuracy',\n",
    "    metric2_col='Recall',\n",
    "    name_metric1='Accuracy (%)',\n",
    "    name_metric2='Recall (%)', \n",
    "    baseline_acc = test_result['Accuracy'].mean(),\n",
    "    sort_by='Accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result['Model'] = test_result['Model'].str.replace('undersampled', '', regex=False).str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, for safety: strip spaces\n",
    "test_result['Model'] = test_result['Model'].str.strip()\n",
    "\n",
    "# Then, keep only the best (highest Accuracy) per Model\n",
    "test_result_cleaned = test_result.sort_values('Accuracy', ascending=False).drop_duplicates(subset=['Model'], keep='first').reset_index(drop=True)\n",
    "\n",
    "test_result_cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env_modern_slavery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
